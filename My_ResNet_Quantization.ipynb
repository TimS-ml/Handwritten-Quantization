{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qI0osRmY9yo_",
    "outputId": "b41ad9bd-a7ee-4120-a5a0-0160286db251"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%xmode Verbose\n",
    "# %xmode Plain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FJvJbxGuxkfL",
    "outputId": "9fac5905-cdd9-4608-df8d-50dc87774a1e"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "if 'google.colab' in sys.modules:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive', force_remount=True)\n",
    "    os.chdir('/content/drive/My Drive/Project/Quantization/')  # replace to your google drive path\n",
    "    print('Env: colab, run colab init')\n",
    "    isColab = True\n",
    "else:\n",
    "    os.chdir('.')\n",
    "    cwd = os.getcwd()\n",
    "    print('Env: local')\n",
    "    isColab = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uEz6aTd2NOIQ"
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "import torch\n",
    "from torch import Tensor\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Function\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "from typing import Type, Callable, Union, List, Optional\n",
    "# from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1jYHtHzbzO7P"
   },
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lBFH541Wxzys",
    "outputId": "f6677ae4-c590-4d21-f1f9-5dfa4ae2104e"
   },
   "outputs": [],
   "source": [
    "# Since currently we are using fp32, theoretically it suports cuda\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device = 'cpu'\n",
    "\n",
    "# for reproduce\n",
    "def set_seed(seed):\n",
    "    # random.seed(seed)\n",
    "    # np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if device == 'cuda':\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f3-jebxkx2QX"
   },
   "outputs": [],
   "source": [
    "quant_activation_bits = 4\n",
    "quant_weight_bits = 4\n",
    "\n",
    "# model save path and prefix\n",
    "savepath = './checkpoint/' + 'ResNet50_2_'\n",
    "modelpath = './checkpoint/ResNet50_93.62_44.pt'  # my pre-trained ResNet50 on GPU\n",
    "save_final_model = False  # save final quantized model or not\n",
    "\n",
    "# for data loader\n",
    "# kwargs = {'num_workers': 2, 'pin_memory': True}\n",
    "kwargs = {'num_workers': 2}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ktrYu011Nlik"
   },
   "source": [
    "# ResNet 50\n",
    "\n",
    "This model can be quantized using PyTorch built-in method. Modified from\n",
    "\n",
    "https://github.com/pytorch/vision/blob/release/0.8.0/torchvision/models/resnet.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q0pS3aXGKHaf",
    "lines_to_next_cell": 2
   },
   "source": [
    "## Bottleneck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Xv9XlX78KJtb",
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "class Bottleneck(nn.Module):\n",
    "    expansion: int = 4\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            inplanes: int,\n",
    "            planes: int,\n",
    "            stride: int = 1,\n",
    "            downsample: Optional[nn.Module] = None,\n",
    "            groups: int = 1,\n",
    "            base_width: int = 64,\n",
    "            dilation: int = 1,\n",
    "            norm_layer: Optional[Callable[..., nn.Module]] = None) -> None:\n",
    "        super(Bottleneck, self).__init__()\n",
    "        if norm_layer is None:\n",
    "            norm_layer = nn.BatchNorm2d\n",
    "        width = int(planes * (base_width / 64.)) * groups\n",
    "        # Both self.conv2 and self.downsample layers downsample the input when stride != 1\n",
    "        self.conv1 = nn.Conv2d(inplanes,\n",
    "                               width,\n",
    "                               kernel_size=1,\n",
    "                               stride=1,\n",
    "                               bias=False)\n",
    "        self.bn1 = norm_layer(width)\n",
    "        self.relu1 = nn.ReLU(inplace=True)\n",
    "        self.conv2 = nn.Conv2d(width,\n",
    "                               width,\n",
    "                               kernel_size=3,\n",
    "                               stride=stride,\n",
    "                               padding=dilation,\n",
    "                               groups=groups,\n",
    "                               bias=False,\n",
    "                               dilation=dilation)\n",
    "        self.bn2 = norm_layer(width)\n",
    "        self.relu2 = nn.ReLU(inplace=True)\n",
    "        self.conv3 = nn.Conv2d(width,\n",
    "                               planes * self.expansion,\n",
    "                               kernel_size=1,\n",
    "                               stride=1,\n",
    "                               bias=False)\n",
    "        self.bn3 = norm_layer(planes * self.expansion)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "        self.float_add = nn.quantized.FloatFunctional()\n",
    "        self.relu3 = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        identity = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu1(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu2(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "\n",
    "        out = self.float_add.add(identity, out)\n",
    "        out = self.relu3(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TDsQtFQGKRg8",
    "lines_to_next_cell": 2
   },
   "source": [
    "## ResNet-50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9_LKJtme95FA"
   },
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            block: Type[Union[Bottleneck]],\n",
    "            layers: List[int],\n",
    "            num_classes: int = 1000,\n",
    "            zero_init_residual: bool = False,\n",
    "            groups: int = 1,\n",
    "            width_per_group: int = 64,\n",
    "            replace_stride_with_dilation: Optional[List[bool]] = None,\n",
    "            norm_layer: Optional[Callable[..., nn.Module]] = None) -> None:\n",
    "        super(ResNet, self).__init__()\n",
    "        if norm_layer is None:\n",
    "            norm_layer = nn.BatchNorm2d\n",
    "        self._norm_layer = norm_layer\n",
    "\n",
    "        self.inplanes = 64\n",
    "        self.dilation = 1\n",
    "        if replace_stride_with_dilation is None:\n",
    "            # each element in the tuple indicates if we should replace\n",
    "            # the 2x2 stride with a dilated convolution instead\n",
    "            replace_stride_with_dilation = [False, False, False]\n",
    "        if len(replace_stride_with_dilation) != 3:\n",
    "            raise ValueError(\"replace_stride_with_dilation should be None \"\n",
    "                             \"or a 3-element tuple, got {}\".format(\n",
    "                                 replace_stride_with_dilation))\n",
    "        self.groups = groups\n",
    "        self.base_width = width_per_group\n",
    "        # self.conv1 = nn.Conv2d(3,\n",
    "        #                        self.inplanes,\n",
    "        #                        kernel_size=7,\n",
    "        #                        stride=2,\n",
    "        #                        padding=3,\n",
    "        #                        bias=False)\n",
    "        self.conv1 = nn.Conv2d(3,\n",
    "                               64,\n",
    "                               kernel_size=3,\n",
    "                               stride=1,\n",
    "                               padding=1,\n",
    "                               bias=False)\n",
    "        self.bn1 = norm_layer(self.inplanes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        # self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.maxpool = nn.Identity()\n",
    "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
    "        self.layer2 = self._make_layer(block,\n",
    "                                       128,\n",
    "                                       layers[1],\n",
    "                                       stride=2,\n",
    "                                       dilate=replace_stride_with_dilation[0])\n",
    "        self.layer3 = self._make_layer(block,\n",
    "                                       256,\n",
    "                                       layers[2],\n",
    "                                       stride=2,\n",
    "                                       dilate=replace_stride_with_dilation[1])\n",
    "        self.layer4 = self._make_layer(block,\n",
    "                                       512,\n",
    "                                       layers[3],\n",
    "                                       stride=2,\n",
    "                                       dilate=replace_stride_with_dilation[2])\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight,\n",
    "                                        mode='fan_out',\n",
    "                                        nonlinearity='relu')\n",
    "            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "        # Zero-initialize the last BN in each residual branch,\n",
    "        # so that the residual branch starts with zeros, and each residual block behaves like an identity.\n",
    "        # This improves the model by 0.2~0.3% according to https://arxiv.org/abs/1706.02677\n",
    "        if zero_init_residual:\n",
    "            for m in self.modules():\n",
    "                if isinstance(m, Bottleneck):\n",
    "                    nn.init.constant_(m.bn3.weight,\n",
    "                                      0)  # type: ignore[arg-type]\n",
    "\n",
    "    def _make_layer(self,\n",
    "                    block: Type[Union[Bottleneck]],\n",
    "                    planes: int,\n",
    "                    blocks: int,\n",
    "                    stride: int = 1,\n",
    "                    dilate: bool = False) -> nn.Sequential:\n",
    "        norm_layer = self._norm_layer\n",
    "        downsample = None\n",
    "        previous_dilation = self.dilation\n",
    "        if dilate:\n",
    "            self.dilation *= stride\n",
    "            stride = 1\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.inplanes,\n",
    "                          planes * block.expansion,\n",
    "                          kernel_size=1,\n",
    "                          stride=stride,\n",
    "                          bias=False),\n",
    "                norm_layer(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(\n",
    "            block(self.inplanes, planes, stride, downsample, self.groups,\n",
    "                  self.base_width, previous_dilation, norm_layer))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(\n",
    "                block(self.inplanes,\n",
    "                      planes,\n",
    "                      groups=self.groups,\n",
    "                      base_width=self.base_width,\n",
    "                      dilation=self.dilation,\n",
    "                      norm_layer=norm_layer))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OfSGlW_WIsz2"
   },
   "outputs": [],
   "source": [
    "model = ResNet(Bottleneck, [3, 4, 6, 3])\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Jy3wHvTPJQ3X",
    "outputId": "e0e54121-29ac-4c9e-a3cf-98fdd310f5a3"
   },
   "outputs": [],
   "source": [
    "# The model is trained on cuda, use `map_location` to load it into CPU\n",
    "checkpoint = torch.load(modelpath, map_location=lambda storage, loc: storage)\n",
    "model.load_state_dict(checkpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XBm6sxwLYQ0U",
    "lines_to_next_cell": 2
   },
   "source": [
    "# Observer Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JRODoK0bIJqZ",
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "class ObserverBase(nn.Module):\n",
    "    def __init__(self, q_level):\n",
    "        super(ObserverBase, self).__init__()\n",
    "        self.q_level = q_level\n",
    "\n",
    "    def update_range(self, min_val, max_val):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def forward(self, input):\n",
    "        if self.q_level == 'Layer':\n",
    "            min_val = torch.min(input)\n",
    "            max_val = torch.max(input)\n",
    "        elif self.q_level == 'Channel':\n",
    "            input = torch.flatten(input, start_dim=1)\n",
    "            min_val = torch.min(input, 1)[0]  # output tensors having 1 fewer dimension than input\n",
    "            max_val = torch.max(input, 1)[0]\n",
    "        elif self.q_level == 'FC':  # for linear channel\n",
    "            min_val = torch.min(input, 1, keepdim=True)[0]\n",
    "            max_val = torch.max(input, 1, keepdim=True)[0]\n",
    "\n",
    "        self.update_range(min_val, max_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mVsrXQjQ_rsc",
    "lines_to_next_cell": 2
   },
   "source": [
    "## MinMax Observer\n",
    "\n",
    "\\begin{array}{ll}\n",
    "x_\\text{min} &= \\begin{cases}\n",
    "    \\min(X) & \\text{if~}x_\\text{min} = \\text{None} \\\\\n",
    "    \\min\\left(x_\\text{min}, \\min(X)\\right) & \\text{otherwise}\n",
    "\\end{cases}\\\\\n",
    "x_\\text{max} &= \\begin{cases}\n",
    "    \\max(X) & \\text{if~}x_\\text{max} = \\text{None} \\\\\n",
    "    \\max\\left(x_\\text{max}, \\max(X)\\right) & \\text{otherwise}\n",
    "\\end{cases}\\\\\n",
    "\\end{array}\n",
    "\n",
    "\n",
    "\\begin{aligned}\n",
    "    \\text{if Symmetric:}&\\\\\n",
    "    &s = 2 \\max(|x_\\text{min}|, x_\\text{max}) /\n",
    "        \\left( Q_\\text{max} - Q_\\text{min} \\right) \\\\\n",
    "    &z = \\begin{cases}\n",
    "        0 & \\text{if dtype is qint8} \\\\\n",
    "        128 & \\text{otherwise}\n",
    "    \\end{cases}\\\\\n",
    "    \\text{Otherwise:}&\\\\\n",
    "        &s = \\left( x_\\text{max} - x_\\text{min}  \\right ) /\n",
    "            \\left( Q_\\text{max} - Q_\\text{min} \\right ) \\\\\n",
    "        &z = Q_\\text{min} - \\text{round}(x_\\text{min} / s)\n",
    "\\end{aligned}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qndlEMhFUGtv",
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# ObserverBase contains a default `forward` function\n",
    "class MinMaxObserver(ObserverBase):\n",
    "    def __init__(self, q_level, out_channels):\n",
    "        super(MinMaxObserver, self).__init__(q_level)\n",
    "        self.num_flag = 0\n",
    "        self.out_channels = out_channels\n",
    "        if self.q_level == 'Layer':\n",
    "            self.min_val = torch.zeros((1), dtype=torch.float32)\n",
    "            self.max_val = torch.zeros((1), dtype=torch.float32)\n",
    "        elif self.q_level == 'Channel':\n",
    "            self.min_val = torch.zeros((out_channels, 1, 1, 1),\n",
    "                                       dtype=torch.float32)\n",
    "            self.max_val = torch.zeros((out_channels, 1, 1, 1),\n",
    "                                       dtype=torch.float32)\n",
    "        elif self.q_level == 'FC':\n",
    "            self.min_val = torch.zeros((out_channels, 1), dtype=torch.float32)\n",
    "            self.max_val = torch.zeros((out_channels, 1), dtype=torch.float32)\n",
    "\n",
    "    def update_range(self, min_val_cur, max_val_cur):\n",
    "        if self.q_level == 'Channel':\n",
    "            min_val_cur.resize_(self.min_val.shape)\n",
    "            max_val_cur.resize_(self.max_val.shape)\n",
    "        if self.num_flag == 0:\n",
    "            self.num_flag += 1\n",
    "            min_val = min_val_cur\n",
    "            max_val = max_val_cur\n",
    "        else:\n",
    "            min_val = torch.min(min_val_cur, self.min_val)\n",
    "            max_val = torch.max(max_val_cur, self.max_val)\n",
    "        self.min_val.copy_(min_val)\n",
    "        self.max_val.copy_(max_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ff1VR9VyIGJz",
    "lines_to_next_cell": 2
   },
   "source": [
    "## Histogram Observer\n",
    "\n",
    "Modified form PyTorch source code. The scale and zero point are computed as follows:\n",
    "\n",
    "1. Create the histogram of the incoming inputs.\n",
    "    - The histogram is computed continuously,\n",
    "    - and the ranges per bin change with every new tensor observed.\n",
    "\n",
    "2. Search the distribution in the histogram for optimal min/max values.\n",
    "    - The search for the min/max values ensures the minimization of the quantization error with respect to the floating point model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pm_DrY7VIejj"
   },
   "outputs": [],
   "source": [
    "class HistogramObserver(nn.Module):\n",
    "    def __init__(self, q_level, out_channels=None, dst_nbins=8):\n",
    "        super(HistogramObserver, self).__init__()\n",
    "        self.num_flag = 0\n",
    "        self.q_level = q_level\n",
    "        self.out_channels = out_channels\n",
    "        self.num_flag = 0\n",
    "        self.min_val = torch.zeros((1), dtype=torch.float32)\n",
    "        self.max_val = torch.zeros((1), dtype=torch.float32)\n",
    "        self.bins = 2048\n",
    "        self.histogram = torch.zeros(self.bins)\n",
    "        self.dst_nbins = dst_nbins\n",
    "\n",
    "    # norm = density * (end^3 - begin^3) / 3\n",
    "    def _get_norm(self, delta_begin, delta_end, density):\n",
    "        norm = (delta_end * delta_end * delta_end -\n",
    "                delta_begin * delta_begin * delta_begin) / 3\n",
    "        return density * norm\n",
    "\n",
    "    # Compute the quantization error if we use start_bin to end_bin as the\n",
    "    # min and max to do the quantization.\n",
    "    def compute_quantization_error(self, next_start_bin, next_end_bin):\n",
    "        bin_width = (self.max_val - self.min_val) / self.bins\n",
    "\n",
    "        dst_bin_width = bin_width * (next_end_bin - next_start_bin +\n",
    "                                     1) / self.dst_nbins\n",
    "        if dst_bin_width == 0.0:\n",
    "            return 0.0\n",
    "\n",
    "        # [1, 2, 3, ...]\n",
    "        src_bin = torch.arange(self.bins)\n",
    "\n",
    "        # `distances` from the beginning of first dst_bin to \n",
    "        #   the beginning and end of src_bin\n",
    "        src_bin_begin = (src_bin - next_start_bin) * bin_width\n",
    "        src_bin_end = src_bin_begin + bin_width\n",
    "\n",
    "        # which dst_bins the beginning and end of src_bin belong to?\n",
    "        dst_bin_of_begin = torch.clamp(src_bin_begin // dst_bin_width, 0,\n",
    "                                       self.dst_nbins - 1)\n",
    "        dst_bin_of_begin_center = (dst_bin_of_begin + 0.5) * dst_bin_width\n",
    "\n",
    "        dst_bin_of_end = torch.clamp(src_bin_end // dst_bin_width, 0,\n",
    "                                     self.dst_nbins - 1)\n",
    "        dst_bin_of_end_center = (dst_bin_of_end + 0.5) * dst_bin_width\n",
    "\n",
    "        density = self.histogram / bin_width\n",
    "\n",
    "        norm = torch.zeros(self.bins)\n",
    "\n",
    "        # norm += d(delta)\n",
    "        delta_begin = src_bin_begin - dst_bin_of_begin_center\n",
    "        delta_end = dst_bin_width / 2\n",
    "        norm += self._get_norm(delta_begin,\n",
    "                               torch.ones(self.bins) * delta_end, \n",
    "                               density)\n",
    "\n",
    "        # norm += d(dst)\n",
    "        norm += (dst_bin_of_end - dst_bin_of_begin - 1) * \\\n",
    "                    self._get_norm(torch.tensor(-dst_bin_width / 2), \n",
    "                                   torch.tensor(dst_bin_width / 2),\n",
    "                                   density)\n",
    "\n",
    "        dst_bin_of_end_center = (dst_bin_of_end * dst_bin_width +\n",
    "                                 dst_bin_width / 2)\n",
    "        delta_begin = -dst_bin_width / 2\n",
    "        delta_end = src_bin_end - dst_bin_of_end_center\n",
    "\n",
    "        # norm += d(new delta)\n",
    "        norm += self._get_norm(torch.tensor(delta_begin), \n",
    "                               delta_end, \n",
    "                               density)\n",
    "\n",
    "        return norm.sum().item()\n",
    "\n",
    "    def non_linear_param_search(self):\n",
    "        bin_width = (self.max_val - self.min_val) / self.bins\n",
    "\n",
    "        # cumulative sum\n",
    "        total = torch.sum(self.histogram).item()\n",
    "        cSum = torch.cumsum(self.histogram, dim=0)\n",
    "\n",
    "        stepsize = 1e-5  # granularity\n",
    "        alpha = 0.0  # lower bound\n",
    "        beta = 1.0  # upper bound\n",
    "        start_bin = 0\n",
    "        end_bin = self.bins - 1\n",
    "        norm_min = float(\"inf\")\n",
    "\n",
    "        while alpha < beta:\n",
    "            # Find the next step\n",
    "            next_alpha = alpha + stepsize\n",
    "            next_beta = beta - stepsize\n",
    "\n",
    "            # find the left and right bins between the quantile bounds\n",
    "            l = start_bin\n",
    "            r = end_bin\n",
    "            while l < end_bin and cSum[l] < next_alpha * total:\n",
    "                l = l + 1\n",
    "            while r > start_bin and cSum[r] > next_beta * total:\n",
    "                r = r - 1\n",
    "\n",
    "            # decide the next move\n",
    "            next_start_bin = start_bin\n",
    "            next_end_bin = end_bin\n",
    "            if (l - start_bin) > (end_bin - r):\n",
    "                # move the start bin\n",
    "                next_start_bin = l\n",
    "                alpha = next_alpha\n",
    "            else:\n",
    "                # move the end bin\n",
    "                next_end_bin = r\n",
    "                beta = next_beta\n",
    "\n",
    "            if next_start_bin == start_bin and next_end_bin == end_bin:\n",
    "                continue\n",
    "\n",
    "            # calculate the quantization error using next_start_bin and next_end_bin\n",
    "            norm = self.compute_quantization_error(next_start_bin,\n",
    "                                                   next_end_bin)\n",
    "\n",
    "            if norm > norm_min:\n",
    "                break\n",
    "            norm_min = norm\n",
    "            start_bin = next_start_bin\n",
    "            end_bin = next_end_bin\n",
    "\n",
    "        new_min = self.min_val + bin_width * start_bin\n",
    "        new_max = self.min_val + bin_width * (end_bin + 1)\n",
    "        return new_min, new_max\n",
    "\n",
    "    def update_range(self, min_val_cur, max_val_cur):\n",
    "        if self.num_flag == 0:\n",
    "            self.num_flag += 1\n",
    "            min_val = min_val_cur\n",
    "            max_val = max_val_cur\n",
    "        else:\n",
    "            min_val = torch.min(min_val_cur, self.min_val)\n",
    "            max_val = torch.max(max_val_cur, self.max_val)\n",
    "        self.min_val.copy_(min_val)\n",
    "        self.max_val.copy_(max_val)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def forward(self, input):\n",
    "        min_val = torch.min(input)\n",
    "        max_val = torch.max(input)\n",
    "        self.update_range(min_val, max_val)\n",
    "        \n",
    "        # Generate histogram\n",
    "        torch.histc(input, self.bins, out=self.histogram)\n",
    "\n",
    "        new_min, new_max = self.non_linear_param_search()\n",
    "        self.update_range(new_min, new_max)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fake Histogram Observer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy it's a Percentile Observer\n",
    "# Since the goal of PyTorch HistogramObserver is to remove outlier, \n",
    "#   so simply choose the specific percentile of a histogram\n",
    "class FakeHistogramObserver(nn.Module):\n",
    "    def __init__(self, q_level, momentum=0.1, out_channels=None, hist_percentile=0.9999):\n",
    "        super(FakeHistogramObserver, self).__init__()\n",
    "        self.momentum = momentum\n",
    "        self.hist_percentile = hist_percentile\n",
    "        self.num_flag = 0\n",
    "        self.q_level = q_level\n",
    "        self.out_channels = out_channels\n",
    "        self.min_val = torch.zeros((1), dtype=torch.float32)\n",
    "        self.max_val = torch.zeros((1), dtype=torch.float32)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def forward(self, input):\n",
    "        # input, k, dim\n",
    "        max_val_cur = torch.kthvalue(input.abs().view(-1),\n",
    "                                     int(self.hist_percentile *\n",
    "                                         input.view(-1).size(0)),\n",
    "                                     dim=0)[0]\n",
    "\n",
    "        if self.num_flag == 0:\n",
    "            self.num_flag += 1\n",
    "            max_val = max_val_cur\n",
    "        else:\n",
    "            max_val = (1 - self.momentum) * self.max_val \\\n",
    "                + self.momentum * max_val_cur\n",
    "        self.max_val.copy_(max_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D9qEFXtwkqMW",
    "lines_to_next_cell": 2
   },
   "source": [
    "# Default Quantizer\n",
    "\n",
    "Clamp all elements in input into the range [ min, max ]\n",
    "\n",
    "https://pytorch.org/docs/stable/generated/torch.clamp.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U4QTbVlLIyWv",
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# This is for QAT, for PTQ use torch.round() is ok\n",
    "# # class Round(Function):\n",
    "# #     @staticmethod\n",
    "# #     def forward(self, input):\n",
    "# #         output = torch.round(input)\n",
    "# #         return output\n",
    "# \n",
    "# #     @staticmethod\n",
    "# #     def backward(self, grad_output):\n",
    "# #         grad_input = grad_output.clone()\n",
    "# #         return grad_input\n",
    "\n",
    "# Symmetric\n",
    "# https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.register_buffer\n",
    "# `register_buffer` should not to be considered a model parameter\n",
    "class Quantizer(nn.Module):\n",
    "    def __init__(self, bits, observer, activation_weight_flag):\n",
    "        super(Quantizer, self).__init__()\n",
    "\n",
    "        self.bits = bits\n",
    "        self.observer = observer\n",
    "        self.activation_weight_flag = activation_weight_flag\n",
    "        # scale/zero_point/eps\n",
    "        if self.observer.q_level == 'Layer':\n",
    "            self.register_buffer(\n",
    "                'scale', \n",
    "                torch.ones((1), \n",
    "                            dtype=torch.float32))\n",
    "            self.register_buffer(\n",
    "                'zero_point',\n",
    "                torch.zeros((1), \n",
    "                            dtype=torch.float32))\n",
    "        elif self.observer.q_level == 'Channel':\n",
    "            self.register_buffer(\n",
    "                'scale',\n",
    "                torch.ones((self.observer.out_channels, 1, 1, 1),\n",
    "                           dtype=torch.float32))\n",
    "            self.register_buffer(\n",
    "                'zero_point',\n",
    "                torch.zeros((self.observer.out_channels, 1, 1, 1),\n",
    "                            dtype=torch.float32))\n",
    "        elif self.observer.q_level == 'FC':\n",
    "            self.register_buffer(\n",
    "                'scale',\n",
    "                torch.ones((self.observer.out_channels, 1),\n",
    "                           dtype=torch.float32))\n",
    "            self.register_buffer(\n",
    "                'zero_point',\n",
    "                torch.zeros((self.observer.out_channels, 1),\n",
    "                            dtype=torch.float32))\n",
    "        self.eps = torch.tensor((torch.finfo(torch.float32).eps),\n",
    "                                dtype=torch.float32)  # eps(1.1921e-07)\n",
    "\n",
    "        if self.activation_weight_flag == 0:  # weight\n",
    "            self.quant_min_val = torch.tensor((-((1 << (self.bits - 1)) - 1)))\n",
    "            self.quant_max_val = torch.tensor(((1 << (self.bits - 1)) - 1))\n",
    "        elif self.activation_weight_flag == 1:  # activation\n",
    "            self.quant_min_val = torch.tensor((-((1 << (self.bits - 1)) - 1)))\n",
    "            self.quant_max_val = torch.tensor(((1 << (self.bits - 1)) - 1))\n",
    "        else:\n",
    "            print('activation_weight_flag error')\n",
    "\n",
    "    def update_qparams(self):\n",
    "        quant_range = float(self.quant_max_val -\n",
    "                            self.quant_min_val) / 2  # quantized_range\n",
    "        float_range = torch.max(torch.abs(self.observer.min_val),\n",
    "                                torch.abs(\n",
    "                                    self.observer.max_val))  # since symmetric, we need max val\n",
    "        self.scale = float_range / quant_range  # scale\n",
    "        self.scale = torch.max(self.scale,\n",
    "                               self.eps)  # processing for very small scale\n",
    "        self.zero_point = torch.zeros_like(self.scale)  # zero_point\n",
    "\n",
    "    # def round(self, input):\n",
    "    #     output = Round.apply(input)\n",
    "    #     return output\n",
    "\n",
    "    def forward(self, input):\n",
    "        if self.training:\n",
    "            self.observer(input)\n",
    "            self.update_qparams()  # update scale and zero_point\n",
    "        # Quantize and DeQuantize\n",
    "        # [1] Quantized value clamp to [quant_min_val, quant_max_val]\n",
    "        # [2] Round to int\n",
    "        # [3] DeQuantize to float\n",
    "        # output = (torch.clamp(self.round(input / self.scale - self.zero_point),\n",
    "        #                       self.quant_min_val, self.quant_max_val) \\\n",
    "        #             + self.zero_point) * self.scale\n",
    "        _output = torch.round(input / self.scale - self.zero_point)\n",
    "        output = (torch.clamp(_output,\n",
    "                              min=int(self.quant_min_val),\n",
    "                              max=int(self.quant_max_val)) \\\n",
    "                        + self.zero_point) * self.scale\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dKTLMebymnbF"
   },
   "source": [
    "# Quantize Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TbNcXcdZYq6i",
    "lines_to_next_cell": 2
   },
   "source": [
    "## QAdaAvgPooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1QSc5j74YqVW",
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "class QAdaAvgPooling2d(nn.AdaptiveAvgPool2d):\n",
    "    def __init__(self, output_size, a_bits=8, hist_percentile=0.9999):\n",
    "        super(QAdaAvgPooling2d, self).__init__(output_size)\n",
    "        self.activation_quantizer = Quantizer(\n",
    "            bits=a_bits,\n",
    "            observer=FakeHistogramObserver(q_level='Layer',\n",
    "                                           hist_percentile=hist_percentile),\n",
    "            # observer=HistogramObserver(q_level='Layer',\n",
    "            #                            dst_nbins=a_bits),\n",
    "            activation_weight_flag=1)\n",
    "\n",
    "    def forward(self, input):\n",
    "        quant_input = self.activation_quantizer(input)\n",
    "        output = F.adaptive_avg_pool2d(quant_input, self.output_size)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eFxe8WLARV3v",
    "lines_to_next_cell": 2
   },
   "source": [
    "## QReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PFa4ptyMRXwO",
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "class QReLU(nn.ReLU):\n",
    "    def __init__(self, inplace=False, a_bits=8, hist_percentile=0.9999):\n",
    "        super(QReLU, self).__init__(inplace)\n",
    "        self.activation_quantizer = Quantizer(\n",
    "            bits=a_bits,\n",
    "            observer=FakeHistogramObserver(q_level='Layer',\n",
    "                                           hist_percentile=hist_percentile),\n",
    "            # observer=HistogramObserver(q_level='Layer',\n",
    "            #                            dst_nbins=a_bits),\n",
    "            activation_weight_flag=1)\n",
    "\n",
    "    def forward(self, input):\n",
    "        quant_input = self.activation_quantizer(input)\n",
    "        output = F.relu(quant_input, self.inplace)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HkhOdss8Ym3N",
    "lines_to_next_cell": 2
   },
   "source": [
    "## QLinear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eF8evdfvYon_",
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# For ResNet50, nn.Linear is for FC layers\n",
    "class QLinear(nn.Linear):\n",
    "    def __init__(self,\n",
    "                 in_features,\n",
    "                 out_features,\n",
    "                 bias=True,\n",
    "                 a_bits=8,\n",
    "                 w_bits=8,\n",
    "                 direct_inference=False,\n",
    "                 hist_percentile=0.9999):\n",
    "        super(QLinear, self).__init__(in_features, out_features, bias)\n",
    "        self.direct_inference = direct_inference\n",
    "        self.activation_quantizer = Quantizer(\n",
    "            bits=a_bits,\n",
    "            observer=FakeHistogramObserver(q_level='Layer',\n",
    "                                           hist_percentile=hist_percentile),\n",
    "            # observer=HistogramObserver(q_level='Layer',\n",
    "            #                            dst_nbins=a_bits),\n",
    "            activation_weight_flag=1)\n",
    "        self.weight_quantizer = Quantizer(bits=w_bits,\n",
    "                                          observer=MinMaxObserver(\n",
    "                                              q_level='FC',\n",
    "                                              out_channels=out_features),\n",
    "                                          activation_weight_flag=0)\n",
    "\n",
    "    def forward(self, input):\n",
    "        quant_input = self.activation_quantizer(input)\n",
    "        if not self.direct_inference:\n",
    "            quant_weight = self.weight_quantizer(self.weight)\n",
    "        else:\n",
    "            quant_weight = self.weight\n",
    "        output = F.linear(quant_input, quant_weight, self.bias)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sDpbKb3BWCYM",
    "lines_to_next_cell": 2
   },
   "source": [
    "## QConv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MLu-f0iPJaUV"
   },
   "outputs": [],
   "source": [
    "class QConv(nn.Conv2d):\n",
    "    def __init__(self,\n",
    "                 in_channels,\n",
    "                 out_channels,\n",
    "                 kernel_size,\n",
    "                 stride=1,\n",
    "                 padding=0,\n",
    "                 dilation=1,\n",
    "                 groups=1,\n",
    "                 bias=True,\n",
    "                 a_bits=8,\n",
    "                 w_bits=8,\n",
    "                 direct_inference=False,\n",
    "                 hist_percentile=0.9999):\n",
    "        super(QConv, self).__init__(in_channels, out_channels, kernel_size,\n",
    "                                    stride, padding, dilation, groups, bias)\n",
    "        self.direct_inference = direct_inference\n",
    "        self.activation_quantizer = Quantizer(\n",
    "            bits=a_bits,\n",
    "            observer=FakeHistogramObserver(q_level='Layer',\n",
    "                                           hist_percentile=hist_percentile),\n",
    "            # observer=HistogramObserver(q_level='Layer',\n",
    "            #                            dst_nbins=a_bits),\n",
    "            activation_weight_flag=1)\n",
    "        self.weight_quantizer = Quantizer(bits=w_bits,\n",
    "                                          observer=MinMaxObserver(\n",
    "                                              q_level='Layer', out_channels=None),\n",
    "                                          activation_weight_flag=0)\n",
    "\n",
    "    def forward(self, input):\n",
    "        quant_input = self.activation_quantizer(input)\n",
    "        if not self.direct_inference:\n",
    "            quant_weight = self.weight_quantizer(self.weight)\n",
    "        else:\n",
    "            quant_weight = self.weight\n",
    "        output = F.conv2d(quant_input, quant_weight, self.bias, self.stride,\n",
    "                          self.padding, self.dilation, self.groups)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lJymgOi3PkCk"
   },
   "source": [
    "# Prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1Q0phpjgfXxp"
   },
   "outputs": [],
   "source": [
    "def Quantize_layer_prepare(module,\n",
    "                           a_bits=8,\n",
    "                           w_bits=8,\n",
    "                           direct_inference=False,\n",
    "                           hist_percentile=0.9999):\n",
    "\n",
    "    for name, child in module.named_children():\n",
    "        # [1] Conv2d\n",
    "        if isinstance(child, nn.Conv2d):\n",
    "            quant_conv = QConv(child.in_channels,\n",
    "                               child.out_channels,\n",
    "                               child.kernel_size,\n",
    "                               stride=child.stride,\n",
    "                               padding=child.padding,\n",
    "                               dilation=child.dilation,\n",
    "                               groups=child.groups,\n",
    "                               bias=False,\n",
    "                               a_bits=a_bits,\n",
    "                               w_bits=w_bits,\n",
    "                               direct_inference=direct_inference,\n",
    "                               hist_percentile=hist_percentile)\n",
    "            quant_conv.weight.data = child.weight\n",
    "            module._modules[name] = quant_conv\n",
    "\n",
    "        # [2] Linear\n",
    "        elif isinstance(child, nn.Linear):\n",
    "            quant_linear = QLinear(child.in_features,\n",
    "                                   child.out_features,\n",
    "                                   bias=True,\n",
    "                                   a_bits=a_bits,\n",
    "                                   w_bits=w_bits,\n",
    "                                   direct_inference=direct_inference,\n",
    "                                   hist_percentile=hist_percentile)\n",
    "            quant_linear.bias.data = child.bias\n",
    "            quant_linear.weight.data = child.weight\n",
    "            module._modules[name] = quant_linear\n",
    "\n",
    "        # [3] ReLU\n",
    "        elif isinstance(child, nn.ReLU):\n",
    "            quant_relu = QReLU(inplace=child.inplace,\n",
    "                               a_bits=a_bits,\n",
    "                               hist_percentile=hist_percentile)\n",
    "            module._modules[name] = quant_relu\n",
    "\n",
    "        # [4] AdaptiveAvgPool2d, that is what we use in resnet\n",
    "        # https://discuss.pytorch.org/t/adaptive-avg-pool2d-vs-avg-pool2d/27011\n",
    "        elif isinstance(child, nn.AdaptiveAvgPool2d):\n",
    "            quant_adaptive_avg_pool = QAdaAvgPooling2d(\n",
    "                output_size=child.output_size,\n",
    "                a_bits=a_bits,\n",
    "                hist_percentile=hist_percentile)\n",
    "            module._modules[name] = quant_adaptive_avg_pool\n",
    "\n",
    "        # [5] Go deeper to the Child\n",
    "        else:\n",
    "            Quantize_layer_prepare(child,\n",
    "                                   a_bits=a_bits,\n",
    "                                   w_bits=w_bits,\n",
    "                                   direct_inference=direct_inference,\n",
    "                                   hist_percentile=hist_percentile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m1DFDMe2Pl9D",
    "outputId": "09b6f707-3b99-452d-9c4a-9e12d3ef6a33"
   },
   "outputs": [],
   "source": [
    "fused_model = copy.deepcopy(model)\n",
    "fused_model.eval()\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gRv7cxlrUMTe",
    "outputId": "54aef915-1c5a-4f3a-d30e-2ab6c04518fb"
   },
   "outputs": [],
   "source": [
    "Quantize_layer_prepare(fused_model, a_bits=quant_activation_bits, w_bits=quant_weight_bits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CBoflvrAYW-j",
    "outputId": "e91add9c-aa3c-4c79-fbd0-d2bcf2f9f426"
   },
   "outputs": [],
   "source": [
    "# The model is quantized and wait for calibration\n",
    "for name, param in fused_model.named_parameters():\n",
    "    print(name, param.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aE8-uGAbfpUS",
    "lines_to_next_cell": 2
   },
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9uDg7261ksZG"
   },
   "outputs": [],
   "source": [
    "# get data\n",
    "def get_CIFAR10(getdata=False):\n",
    "    input_size = 32\n",
    "    num_classes = 10\n",
    "    normalize = transforms.Normalize((0.4914, 0.4822, 0.4465),\n",
    "                                     (0.2023, 0.1994, 0.2010))\n",
    "\n",
    "    train_transform = transforms.Compose([\n",
    "        transforms.RandomCrop(32, padding=4),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ])\n",
    "    train_dataset = datasets.CIFAR10(root='./data',\n",
    "                                     train=True,\n",
    "                                     transform=train_transform,\n",
    "                                     download=getdata)\n",
    "\n",
    "    test_transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ])\n",
    "    test_dataset = datasets.CIFAR10(root='./data',\n",
    "                                    train=False,\n",
    "                                    transform=test_transform,\n",
    "                                    download=getdata)\n",
    "\n",
    "    return input_size, num_classes, train_dataset, test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VY3ARl_0kywt"
   },
   "outputs": [],
   "source": [
    "input_size, num_classes, train_dataset, test_dataset = get_CIFAR10()\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset,\n",
    "                                           batch_size=128,\n",
    "                                           shuffle=True,\n",
    "                                           **kwargs)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset,\n",
    "                                          batch_size=128,\n",
    "                                          shuffle=False,\n",
    "                                          **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hm-0PVSuX-O7",
    "lines_to_next_cell": 2
   },
   "source": [
    "# Calib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "On9QGK86X9mJ",
    "outputId": "e2ab4789-56aa-4510-e32f-81e34554b82e"
   },
   "outputs": [],
   "source": [
    "def calib_model_n_liter(batch_num_liter=50):\n",
    "    fused_model.train()\n",
    "\n",
    "    batch_num = 0\n",
    "    for data, _ in train_loader:\n",
    "        _ = fused_model(data)\n",
    "\n",
    "        batch_num += 1\n",
    "        if batch_num > batch_num_liter:\n",
    "            break\n",
    "        if batch_num % 5 == 0:\n",
    "            print('Batch:', batch_num)\n",
    "    return\n",
    "\n",
    "\n",
    "def test():\n",
    "    fused_model.eval()\n",
    "    fused_model.to(device)\n",
    "\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "\n",
    "    for data, target in test_loader:\n",
    "        with torch.no_grad():\n",
    "            outputs = fused_model(data)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "\n",
    "            test_loss += criterion(outputs, target).item() * data.size(0)\n",
    "            correct += torch.sum(preds == target.data)\n",
    "\n",
    "    test_loss = test_loss / len(test_loader.dataset)\n",
    "    test_acc = 100.0 * correct / len(test_loader.dataset)\n",
    "\n",
    "    print('Test Loss: {:.4f}, Accuracy: {:.2f}%'.format(test_loss, test_acc))\n",
    "\n",
    "    return test_loss, test_acc\n",
    "\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "calib_model_n_liter()\n",
    "test_loss, test_acc = test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gVMlHxCrq0FA"
   },
   "outputs": [],
   "source": [
    "if save_final_model:\n",
    "    torch.save(fused_model.state_dict(),\n",
    "               savepath + '{}a-{}w-bit_{:.2f}.pt'.format(\n",
    "                                                     quant_activation_bits,\n",
    "                                                     quant_weight_bits,\n",
    "                                                     test_acc))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Q_v2.ipynb",
   "provenance": []
  },
  "jupytext": {
   "encoding": "# -*- coding: utf-8 -*-",
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
