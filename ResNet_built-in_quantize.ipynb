{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TjjTTlkyxfIr"
   },
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 619,
     "status": "ok",
     "timestamp": 1620739085310,
     "user": {
      "displayName": "Tim Shen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgNQrJ7jwDo36WwiK5d1fd2sl5mNxpQC8UsAvxjZw=s64",
      "userId": "18284420496267004524"
     },
     "user_tz": 240
    },
    "id": "tK_s3yloxgYI",
    "outputId": "d79a07a8-5052-43af-818a-342498803564"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception reporting mode: Verbose\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%xmode Verbose\n",
    "# %xmode Plain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 26866,
     "status": "ok",
     "timestamp": 1620739111569,
     "user": {
      "displayName": "Tim Shen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgNQrJ7jwDo36WwiK5d1fd2sl5mNxpQC8UsAvxjZw=s64",
      "userId": "18284420496267004524"
     },
     "user_tz": 240
    },
    "id": "FJvJbxGuxkfL",
    "outputId": "19bdb07f-6f1a-4097-c9a2-494c82c013ba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n",
      "Env: colab, run colab init\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "if 'google.colab' in sys.modules:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive', force_remount=True)\n",
    "    os.chdir('/content/drive/My Drive/Project/Quantization/')\n",
    "    print('Env: colab, run colab init')\n",
    "    isColab = True\n",
    "else:\n",
    "    os.chdir('.')\n",
    "    cwd = os.getcwd()\n",
    "    print('Env: local')\n",
    "    isColab = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XBteJ9JEkWSD"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import models, datasets, transforms\n",
    "\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a5JEXwXa52i5"
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "from torch import Tensor\n",
    "from typing import Type, Any, Callable, Union, List, Optional"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1jYHtHzbzO7P"
   },
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 30307,
     "status": "ok",
     "timestamp": 1620739115042,
     "user": {
      "displayName": "Tim Shen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgNQrJ7jwDo36WwiK5d1fd2sl5mNxpQC8UsAvxjZw=s64",
      "userId": "18284420496267004524"
     },
     "user_tz": 240
    },
    "id": "lBFH541Wxzys",
    "outputId": "73912b6d-e05f-4f40-c2be-23a44380b198"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device:  cpu\n"
     ]
    }
   ],
   "source": [
    "def set_seed(seed):\n",
    "    # random.seed(seed)\n",
    "    # np.random.seed(seed)\n",
    "    # torch.backends.cudnn.deterministic = True\n",
    "    # torch.backends.cudnn.benchmark = False\n",
    "    torch.manual_seed(seed)\n",
    "\n",
    "set_seed(42)\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print('Device: ', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f3-jebxkx2QX"
   },
   "outputs": [],
   "source": [
    "# model save path and prefix\n",
    "savepath = './checkpoint/' + 'ResNet50_2_'\n",
    "modelpath = './checkpoint/ResNet50_93.62_44.pt'\n",
    "\n",
    "kwargs = {'num_workers': 2, 'pin_memory': True}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FavcFxpDmIwn"
   },
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l5dVwcQZmKM8"
   },
   "outputs": [],
   "source": [
    "def calibrate_model(model, loader, device=torch.device('cpu')):\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    for inputs, labels in loader:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        _ = model(inputs)\n",
    "\n",
    "def calibrate_model_n_liter(model, loader, device=torch.device('cpu'), count=3):\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    # short calibration\n",
    "    for inputs, labels in loader:\n",
    "        if count > 0:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            _ = model(inputs)\n",
    "            count -= 1\n",
    "        else:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wlkfcen6zBCs"
   },
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9uDg7261ksZG"
   },
   "outputs": [],
   "source": [
    "def get_CIFAR10(getdata=False):\n",
    "    input_size = 32\n",
    "    num_classes = 10\n",
    "    normalize = transforms.Normalize((0.4914, 0.4822, 0.4465), \n",
    "                                     (0.2023, 0.1994, 0.2010))\n",
    "    \n",
    "    train_transform = transforms.Compose([\n",
    "            transforms.RandomCrop(32, padding=4),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            normalize,\n",
    "        ])\n",
    "    train_dataset = datasets.CIFAR10(\n",
    "        root='./data', train=True, transform=train_transform, download=getdata\n",
    "    )\n",
    "\n",
    "    test_transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            normalize,\n",
    "        ])\n",
    "    test_dataset = datasets.CIFAR10(\n",
    "        root='./data', train=False, transform=test_transform, download=getdata\n",
    "    )\n",
    "\n",
    "    return input_size, num_classes, train_dataset, test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VY3ARl_0kywt"
   },
   "outputs": [],
   "source": [
    "input_size, num_classes, train_dataset, test_dataset = get_CIFAR10()\n",
    "\n",
    "# train_loader = torch.utils.data.DataLoader(\n",
    "#     train_dataset, batch_size=128, shuffle=True, **kwargs\n",
    "# )\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_dataset, batch_size=128, shuffle=False, **kwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3YVCcfO0dArp"
   },
   "outputs": [],
   "source": [
    "temp_data, temp_target = next(iter(test_loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9_8Pwbd7xfPQ"
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v8-icgFAsTkg"
   },
   "outputs": [],
   "source": [
    "# A modify version of original Pytorch Source Code\n",
    "# https://github.com/pytorch/vision/blob/release/0.8.0/torchvision/models/resnet.py\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    expansion: int = 4\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            inplanes: int,\n",
    "            planes: int,\n",
    "            stride: int = 1,\n",
    "            downsample: Optional[nn.Module] = None,\n",
    "            groups: int = 1,\n",
    "            base_width: int = 64,\n",
    "            dilation: int = 1,\n",
    "            norm_layer: Optional[Callable[..., nn.Module]] = None) -> None:\n",
    "        super(Bottleneck, self).__init__()\n",
    "        if norm_layer is None:\n",
    "            norm_layer = nn.BatchNorm2d\n",
    "        width = int(planes * (base_width / 64.)) * groups\n",
    "        # Both self.conv2 and self.downsample layers downsample the input when stride != 1\n",
    "        self.conv1 = nn.Conv2d(inplanes, width, \n",
    "                               kernel_size=1, stride=1, bias=False)\n",
    "        self.bn1 = norm_layer(width)\n",
    "        self.relu1 = nn.ReLU(inplace=True)\n",
    "        self.conv2 = nn.Conv2d(width, width, \n",
    "                               kernel_size=3,\n",
    "                               stride=stride,\n",
    "                               padding=dilation,\n",
    "                               groups=groups,\n",
    "                               bias=False,\n",
    "                               dilation=dilation)\n",
    "        self.bn2 = norm_layer(width)\n",
    "        self.relu2 = nn.ReLU(inplace=True)\n",
    "        self.conv3 = nn.Conv2d(width, planes * self.expansion, \n",
    "                               kernel_size=1, stride=1, bias=False)\n",
    "        self.bn3 = norm_layer(planes * self.expansion)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "        self.float_add = nn.quantized.FloatFunctional()\n",
    "        self.relu3 = nn.ReLU(inplace=True)\n",
    "        \n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        identity = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu1(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu2(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "\n",
    "        out = self.float_add.add(identity, out)\n",
    "        out = self.relu3(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gkQgQIV-z6_x"
   },
   "outputs": [],
   "source": [
    "model = models.resnet._resnet('resnet50', Bottleneck, [3, 4, 6, 3], False, True)\n",
    "\n",
    "model.conv1 = torch.nn.Conv2d(\n",
    "    3, 64, kernel_size=3, stride=1, padding=1, bias=False\n",
    ")\n",
    "model.maxpool = torch.nn.Identity()\n",
    "# model.fc = nn.Sequential(\n",
    "#     nn.Linear(in_features=2048, out_features=10, bias=True),\n",
    "#     nn.LogSoftmax(dim=1)\n",
    "# )\n",
    "\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mz7HwkjRcKZ3"
   },
   "source": [
    "## Examine Statedict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 40953,
     "status": "ok",
     "timestamp": 1620739125739,
     "user": {
      "displayName": "Tim Shen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgNQrJ7jwDo36WwiK5d1fd2sl5mNxpQC8UsAvxjZw=s64",
      "userId": "18284420496267004524"
     },
     "user_tz": 240
    },
    "id": "O_u48ID_aLvm",
    "outputId": "d5407186-aea6-460d-a203-4e7e65615374"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 15,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checkpoint = torch.load(modelpath, map_location=torch.device('cpu'))\n",
    "checkpoint = torch.load(modelpath, map_location=lambda storage, loc: storage)\n",
    "model.load_state_dict(checkpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZF5Y66MT0-39"
   },
   "source": [
    "### Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 40943,
     "status": "ok",
     "timestamp": 1620739125740,
     "user": {
      "displayName": "Tim Shen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgNQrJ7jwDo36WwiK5d1fd2sl5mNxpQC8UsAvxjZw=s64",
      "userId": "18284420496267004524"
     },
     "user_tz": 240
    },
    "id": "sTIT4sPmathh",
    "outputId": "a84f3f90-6e0e-4a61-e69c-750f29eeebb9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): Identity()\n",
      "  (layer1): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (float_add): FloatFunctional(\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "      (relu3): ReLU(inplace=True)\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (float_add): FloatFunctional(\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "      (relu3): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (float_add): FloatFunctional(\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "      (relu3): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (float_add): FloatFunctional(\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "      (relu3): ReLU(inplace=True)\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (float_add): FloatFunctional(\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "      (relu3): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (float_add): FloatFunctional(\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "      (relu3): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (float_add): FloatFunctional(\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "      (relu3): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (float_add): FloatFunctional(\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "      (relu3): ReLU(inplace=True)\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (float_add): FloatFunctional(\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "      (relu3): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (float_add): FloatFunctional(\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "      (relu3): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (float_add): FloatFunctional(\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "      (relu3): ReLU(inplace=True)\n",
      "    )\n",
      "    (4): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (float_add): FloatFunctional(\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "      (relu3): ReLU(inplace=True)\n",
      "    )\n",
      "    (5): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (float_add): FloatFunctional(\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "      (relu3): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (float_add): FloatFunctional(\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "      (relu3): ReLU(inplace=True)\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (float_add): FloatFunctional(\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "      (relu3): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu1): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu2): ReLU(inplace=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (float_add): FloatFunctional(\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "      (relu3): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# for m in model.modules():\n",
    "#     print(m)\n",
    "#     # if isinstance(m, nn.Conv2d):\n",
    "#     #     print(m)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wLgaSNUA1ETi"
   },
   "source": [
    "### Param shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 40932,
     "status": "ok",
     "timestamp": 1620739125740,
     "user": {
      "displayName": "Tim Shen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgNQrJ7jwDo36WwiK5d1fd2sl5mNxpQC8UsAvxjZw=s64",
      "userId": "18284420496267004524"
     },
     "user_tz": 240
    },
    "id": "UCee8Bl8cV4R",
    "outputId": "7deb0da7-85ca-4826-d815-785d4c4012c2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.weight torch.Size([64, 3, 3, 3])\n",
      "bn1.weight torch.Size([64])\n",
      "bn1.bias torch.Size([64])\n",
      "layer1.0.conv1.weight torch.Size([64, 64, 1, 1])\n",
      "layer1.0.bn1.weight torch.Size([64])\n",
      "layer1.0.bn1.bias torch.Size([64])\n",
      "layer1.0.conv2.weight torch.Size([64, 64, 3, 3])\n",
      "layer1.0.bn2.weight torch.Size([64])\n",
      "layer1.0.bn2.bias torch.Size([64])\n",
      "layer1.0.conv3.weight torch.Size([256, 64, 1, 1])\n",
      "layer1.0.bn3.weight torch.Size([256])\n",
      "layer1.0.bn3.bias torch.Size([256])\n",
      "layer1.0.downsample.0.weight torch.Size([256, 64, 1, 1])\n",
      "layer1.0.downsample.1.weight torch.Size([256])\n",
      "layer1.0.downsample.1.bias torch.Size([256])\n",
      "layer1.1.conv1.weight torch.Size([64, 256, 1, 1])\n",
      "layer1.1.bn1.weight torch.Size([64])\n",
      "layer1.1.bn1.bias torch.Size([64])\n",
      "layer1.1.conv2.weight torch.Size([64, 64, 3, 3])\n",
      "layer1.1.bn2.weight torch.Size([64])\n",
      "layer1.1.bn2.bias torch.Size([64])\n",
      "layer1.1.conv3.weight torch.Size([256, 64, 1, 1])\n",
      "layer1.1.bn3.weight torch.Size([256])\n",
      "layer1.1.bn3.bias torch.Size([256])\n",
      "layer1.2.conv1.weight torch.Size([64, 256, 1, 1])\n",
      "layer1.2.bn1.weight torch.Size([64])\n",
      "layer1.2.bn1.bias torch.Size([64])\n",
      "layer1.2.conv2.weight torch.Size([64, 64, 3, 3])\n",
      "layer1.2.bn2.weight torch.Size([64])\n",
      "layer1.2.bn2.bias torch.Size([64])\n",
      "layer1.2.conv3.weight torch.Size([256, 64, 1, 1])\n",
      "layer1.2.bn3.weight torch.Size([256])\n",
      "layer1.2.bn3.bias torch.Size([256])\n",
      "layer2.0.conv1.weight torch.Size([128, 256, 1, 1])\n",
      "layer2.0.bn1.weight torch.Size([128])\n",
      "layer2.0.bn1.bias torch.Size([128])\n",
      "layer2.0.conv2.weight torch.Size([128, 128, 3, 3])\n",
      "layer2.0.bn2.weight torch.Size([128])\n",
      "layer2.0.bn2.bias torch.Size([128])\n",
      "layer2.0.conv3.weight torch.Size([512, 128, 1, 1])\n",
      "layer2.0.bn3.weight torch.Size([512])\n",
      "layer2.0.bn3.bias torch.Size([512])\n",
      "layer2.0.downsample.0.weight torch.Size([512, 256, 1, 1])\n",
      "layer2.0.downsample.1.weight torch.Size([512])\n",
      "layer2.0.downsample.1.bias torch.Size([512])\n",
      "layer2.1.conv1.weight torch.Size([128, 512, 1, 1])\n",
      "layer2.1.bn1.weight torch.Size([128])\n",
      "layer2.1.bn1.bias torch.Size([128])\n",
      "layer2.1.conv2.weight torch.Size([128, 128, 3, 3])\n",
      "layer2.1.bn2.weight torch.Size([128])\n",
      "layer2.1.bn2.bias torch.Size([128])\n",
      "layer2.1.conv3.weight torch.Size([512, 128, 1, 1])\n",
      "layer2.1.bn3.weight torch.Size([512])\n",
      "layer2.1.bn3.bias torch.Size([512])\n",
      "layer2.2.conv1.weight torch.Size([128, 512, 1, 1])\n",
      "layer2.2.bn1.weight torch.Size([128])\n",
      "layer2.2.bn1.bias torch.Size([128])\n",
      "layer2.2.conv2.weight torch.Size([128, 128, 3, 3])\n",
      "layer2.2.bn2.weight torch.Size([128])\n",
      "layer2.2.bn2.bias torch.Size([128])\n",
      "layer2.2.conv3.weight torch.Size([512, 128, 1, 1])\n",
      "layer2.2.bn3.weight torch.Size([512])\n",
      "layer2.2.bn3.bias torch.Size([512])\n",
      "layer2.3.conv1.weight torch.Size([128, 512, 1, 1])\n",
      "layer2.3.bn1.weight torch.Size([128])\n",
      "layer2.3.bn1.bias torch.Size([128])\n",
      "layer2.3.conv2.weight torch.Size([128, 128, 3, 3])\n",
      "layer2.3.bn2.weight torch.Size([128])\n",
      "layer2.3.bn2.bias torch.Size([128])\n",
      "layer2.3.conv3.weight torch.Size([512, 128, 1, 1])\n",
      "layer2.3.bn3.weight torch.Size([512])\n",
      "layer2.3.bn3.bias torch.Size([512])\n",
      "layer3.0.conv1.weight torch.Size([256, 512, 1, 1])\n",
      "layer3.0.bn1.weight torch.Size([256])\n",
      "layer3.0.bn1.bias torch.Size([256])\n",
      "layer3.0.conv2.weight torch.Size([256, 256, 3, 3])\n",
      "layer3.0.bn2.weight torch.Size([256])\n",
      "layer3.0.bn2.bias torch.Size([256])\n",
      "layer3.0.conv3.weight torch.Size([1024, 256, 1, 1])\n",
      "layer3.0.bn3.weight torch.Size([1024])\n",
      "layer3.0.bn3.bias torch.Size([1024])\n",
      "layer3.0.downsample.0.weight torch.Size([1024, 512, 1, 1])\n",
      "layer3.0.downsample.1.weight torch.Size([1024])\n",
      "layer3.0.downsample.1.bias torch.Size([1024])\n",
      "layer3.1.conv1.weight torch.Size([256, 1024, 1, 1])\n",
      "layer3.1.bn1.weight torch.Size([256])\n",
      "layer3.1.bn1.bias torch.Size([256])\n",
      "layer3.1.conv2.weight torch.Size([256, 256, 3, 3])\n",
      "layer3.1.bn2.weight torch.Size([256])\n",
      "layer3.1.bn2.bias torch.Size([256])\n",
      "layer3.1.conv3.weight torch.Size([1024, 256, 1, 1])\n",
      "layer3.1.bn3.weight torch.Size([1024])\n",
      "layer3.1.bn3.bias torch.Size([1024])\n",
      "layer3.2.conv1.weight torch.Size([256, 1024, 1, 1])\n",
      "layer3.2.bn1.weight torch.Size([256])\n",
      "layer3.2.bn1.bias torch.Size([256])\n",
      "layer3.2.conv2.weight torch.Size([256, 256, 3, 3])\n",
      "layer3.2.bn2.weight torch.Size([256])\n",
      "layer3.2.bn2.bias torch.Size([256])\n",
      "layer3.2.conv3.weight torch.Size([1024, 256, 1, 1])\n",
      "layer3.2.bn3.weight torch.Size([1024])\n",
      "layer3.2.bn3.bias torch.Size([1024])\n",
      "layer3.3.conv1.weight torch.Size([256, 1024, 1, 1])\n",
      "layer3.3.bn1.weight torch.Size([256])\n",
      "layer3.3.bn1.bias torch.Size([256])\n",
      "layer3.3.conv2.weight torch.Size([256, 256, 3, 3])\n",
      "layer3.3.bn2.weight torch.Size([256])\n",
      "layer3.3.bn2.bias torch.Size([256])\n",
      "layer3.3.conv3.weight torch.Size([1024, 256, 1, 1])\n",
      "layer3.3.bn3.weight torch.Size([1024])\n",
      "layer3.3.bn3.bias torch.Size([1024])\n",
      "layer3.4.conv1.weight torch.Size([256, 1024, 1, 1])\n",
      "layer3.4.bn1.weight torch.Size([256])\n",
      "layer3.4.bn1.bias torch.Size([256])\n",
      "layer3.4.conv2.weight torch.Size([256, 256, 3, 3])\n",
      "layer3.4.bn2.weight torch.Size([256])\n",
      "layer3.4.bn2.bias torch.Size([256])\n",
      "layer3.4.conv3.weight torch.Size([1024, 256, 1, 1])\n",
      "layer3.4.bn3.weight torch.Size([1024])\n",
      "layer3.4.bn3.bias torch.Size([1024])\n",
      "layer3.5.conv1.weight torch.Size([256, 1024, 1, 1])\n",
      "layer3.5.bn1.weight torch.Size([256])\n",
      "layer3.5.bn1.bias torch.Size([256])\n",
      "layer3.5.conv2.weight torch.Size([256, 256, 3, 3])\n",
      "layer3.5.bn2.weight torch.Size([256])\n",
      "layer3.5.bn2.bias torch.Size([256])\n",
      "layer3.5.conv3.weight torch.Size([1024, 256, 1, 1])\n",
      "layer3.5.bn3.weight torch.Size([1024])\n",
      "layer3.5.bn3.bias torch.Size([1024])\n",
      "layer4.0.conv1.weight torch.Size([512, 1024, 1, 1])\n",
      "layer4.0.bn1.weight torch.Size([512])\n",
      "layer4.0.bn1.bias torch.Size([512])\n",
      "layer4.0.conv2.weight torch.Size([512, 512, 3, 3])\n",
      "layer4.0.bn2.weight torch.Size([512])\n",
      "layer4.0.bn2.bias torch.Size([512])\n",
      "layer4.0.conv3.weight torch.Size([2048, 512, 1, 1])\n",
      "layer4.0.bn3.weight torch.Size([2048])\n",
      "layer4.0.bn3.bias torch.Size([2048])\n",
      "layer4.0.downsample.0.weight torch.Size([2048, 1024, 1, 1])\n",
      "layer4.0.downsample.1.weight torch.Size([2048])\n",
      "layer4.0.downsample.1.bias torch.Size([2048])\n",
      "layer4.1.conv1.weight torch.Size([512, 2048, 1, 1])\n",
      "layer4.1.bn1.weight torch.Size([512])\n",
      "layer4.1.bn1.bias torch.Size([512])\n",
      "layer4.1.conv2.weight torch.Size([512, 512, 3, 3])\n",
      "layer4.1.bn2.weight torch.Size([512])\n",
      "layer4.1.bn2.bias torch.Size([512])\n",
      "layer4.1.conv3.weight torch.Size([2048, 512, 1, 1])\n",
      "layer4.1.bn3.weight torch.Size([2048])\n",
      "layer4.1.bn3.bias torch.Size([2048])\n",
      "layer4.2.conv1.weight torch.Size([512, 2048, 1, 1])\n",
      "layer4.2.bn1.weight torch.Size([512])\n",
      "layer4.2.bn1.bias torch.Size([512])\n",
      "layer4.2.conv2.weight torch.Size([512, 512, 3, 3])\n",
      "layer4.2.bn2.weight torch.Size([512])\n",
      "layer4.2.bn2.bias torch.Size([512])\n",
      "layer4.2.conv3.weight torch.Size([2048, 512, 1, 1])\n",
      "layer4.2.bn3.weight torch.Size([2048])\n",
      "layer4.2.bn3.bias torch.Size([2048])\n",
      "fc.weight torch.Size([1000, 2048])\n",
      "fc.bias torch.Size([1000])\n"
     ]
    }
   ],
   "source": [
    "# or: for param in model.parameters()\n",
    "for name, param in model.named_parameters():\n",
    "    print(name, param.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ivBPzHOq0Ish"
   },
   "source": [
    "### Conv\n",
    "\n",
    "Both self.conv1 and self.downsample layers downsample the input when stride != 1\n",
    "\n",
    "```python\n",
    "if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "    downsample = nn.Sequential(\n",
    "        conv1x1(self.inplanes, planes * block.expansion, stride),\n",
    "        norm_layer(planes * block.expansion),\n",
    "    )\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B4GCV-eUw7j3"
   },
   "outputs": [],
   "source": [
    "# model.conv1?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 453,
     "status": "ok",
     "timestamp": 1620795824342,
     "user": {
      "displayName": "Tim Shen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgNQrJ7jwDo36WwiK5d1fd2sl5mNxpQC8UsAvxjZw=s64",
      "userId": "18284420496267004524"
     },
     "user_tz": 240
    },
    "id": "PfNRd5fs0LMi",
    "outputId": "6108ae68-e18b-4416-f2e4-479ad13efbee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 3, 3, 3])\n",
      "Parameter containing:\n",
      "tensor([[[[ 0.0170,  0.0322,  0.0373],\n",
      "          [ 0.0524,  0.0702,  0.0633],\n",
      "          [ 0.0215,  0.0665,  0.0463]],\n",
      "\n",
      "         [[-0.0093,  0.0030,  0.0114],\n",
      "          [ 0.0089,  0.0259,  0.0148],\n",
      "          [-0.0162, -0.0069,  0.0016]],\n",
      "\n",
      "         [[-0.0068, -0.0046, -0.0009],\n",
      "          [ 0.0087,  0.0030, -0.0065],\n",
      "          [-0.0124, -0.0268, -0.0079]]],\n",
      "\n",
      "\n",
      "        [[[-0.2928,  0.0568,  0.0551],\n",
      "          [-0.0270,  0.7221,  0.5164],\n",
      "          [-0.1322,  0.4442,  0.3527]],\n",
      "\n",
      "         [[-0.0012, -0.2651, -0.1953],\n",
      "          [-0.1325, -0.3407, -0.3702],\n",
      "          [ 0.0156, -0.3355, -0.1800]],\n",
      "\n",
      "         [[ 0.2756,  0.1948,  0.1828],\n",
      "          [ 0.2136,  0.0059, -0.0479],\n",
      "          [ 0.0997, -0.2444, -0.2038]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0121,  0.0083,  0.0228],\n",
      "          [-0.0665,  0.2140,  0.1999],\n",
      "          [-0.1181, -0.0997,  0.0364]],\n",
      "\n",
      "         [[-0.0829,  0.0061,  0.1043],\n",
      "          [-0.1747,  0.1208,  0.2339],\n",
      "          [-0.2115, -0.2244,  0.0199]],\n",
      "\n",
      "         [[-0.0326,  0.0011,  0.0448],\n",
      "          [-0.0548,  0.1854,  0.2360],\n",
      "          [-0.1531, -0.0965,  0.0699]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.0267, -0.0317, -0.0039],\n",
      "          [-0.0157,  0.0429, -0.0019],\n",
      "          [-0.0350, -0.0051, -0.0205]],\n",
      "\n",
      "         [[-0.0132,  0.0100,  0.0119],\n",
      "          [ 0.0226,  0.0641,  0.0373],\n",
      "          [-0.0156,  0.0096,  0.0060]],\n",
      "\n",
      "         [[ 0.0062,  0.0259, -0.0053],\n",
      "          [ 0.0402,  0.0725,  0.0590],\n",
      "          [ 0.0247,  0.0196,  0.0388]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0399,  0.2592,  0.1677],\n",
      "          [ 0.0664,  0.2285,  0.1344],\n",
      "          [-0.1416, -0.3327, -0.2582]],\n",
      "\n",
      "         [[ 0.1248,  0.3097,  0.2120],\n",
      "          [ 0.0809,  0.1510,  0.0140],\n",
      "          [-0.1889, -0.4440, -0.3749]],\n",
      "\n",
      "         [[ 0.0556,  0.2119,  0.1811],\n",
      "          [ 0.1009,  0.1268,  0.0650],\n",
      "          [-0.1099, -0.2766, -0.2328]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0087,  0.0877,  0.0376],\n",
      "          [ 0.0207, -0.0072,  0.0387],\n",
      "          [-0.0142, -0.0119,  0.0105]],\n",
      "\n",
      "         [[ 0.0139, -0.0829, -0.0016],\n",
      "          [-0.0648, -0.2815, -0.1097],\n",
      "          [-0.0016, -0.1688, -0.0720]],\n",
      "\n",
      "         [[ 0.0317,  0.0175, -0.0133],\n",
      "          [ 0.0437, -0.0581, -0.0156],\n",
      "          [ 0.0636, -0.0401,  0.0208]]]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(model.conv1.weight.shape)\n",
    "print(model.conv1.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 41069,
     "status": "ok",
     "timestamp": 1620739125906,
     "user": {
      "displayName": "Tim Shen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgNQrJ7jwDo36WwiK5d1fd2sl5mNxpQC8UsAvxjZw=s64",
      "userId": "18284420496267004524"
     },
     "user_tz": 240
    },
    "id": "ZTiQ15Zw1vdh",
    "outputId": "ee41d6e7-40f0-42e2-dea7-0f344304c3dc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 64, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "print(model.layer1[0].conv1.weight.shape)\n",
    "# print(model.layer1[0].conv1.weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KGzkOu8Y02ZT"
   },
   "source": [
    "### BN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 41059,
     "status": "ok",
     "timestamp": 1620739125907,
     "user": {
      "displayName": "Tim Shen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgNQrJ7jwDo36WwiK5d1fd2sl5mNxpQC8UsAvxjZw=s64",
      "userId": "18284420496267004524"
     },
     "user_tz": 240
    },
    "id": "g1tVAVmL2Crv",
    "outputId": "d08e02f5-d42e-4736-b91a-eac6f116376c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64])\n",
      "torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "print(model.bn1.weight.shape)\n",
    "print(model.bn1.bias.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 41162,
     "status": "ok",
     "timestamp": 1620739126021,
     "user": {
      "displayName": "Tim Shen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgNQrJ7jwDo36WwiK5d1fd2sl5mNxpQC8UsAvxjZw=s64",
      "userId": "18284420496267004524"
     },
     "user_tz": 240
    },
    "id": "WTqscc6pSIzy",
    "outputId": "db77bf21-e7d6-4602-b2a6-4ad99a7a6ce3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([0.0606, 0.0601, 0.1101, 0.0981, 0.0717, 0.0783, 0.1254, 0.0683, 0.0662,\n",
      "        0.0809, 0.0734, 0.0693, 0.0832, 0.0561, 0.0784, 0.0765, 0.0680, 0.0571,\n",
      "        0.0972, 0.0857, 0.0717, 0.0668, 0.0690, 0.0959, 0.0908, 0.0626, 0.0805,\n",
      "        0.0602, 0.1032, 0.0596, 0.0688, 0.0783, 0.0572, 0.0795, 0.0853, 0.0607,\n",
      "        0.0656, 0.0878, 0.0990, 0.0750, 0.0893, 0.1053, 0.0926, 0.0853, 0.0498,\n",
      "        0.0845, 0.0586, 0.0741, 0.0685, 0.0757, 0.0831, 0.0604, 0.0708, 0.0737,\n",
      "        0.1181, 0.0948, 0.0747, 0.0632, 0.1056, 0.0596, 0.0954, 0.0965, 0.0957,\n",
      "        0.0785, 0.0772, 0.0686, 0.1035, 0.0773, 0.0769, 0.0889, 0.0527, 0.0926,\n",
      "        0.0622, 0.1122, 0.0601, 0.0730, 0.0834, 0.0684, 0.0607, 0.0826, 0.0589,\n",
      "        0.1024, 0.0760, 0.0736, 0.0649, 0.0849, 0.0516, 0.0745, 0.1141, 0.0465,\n",
      "        0.0595, 0.0759, 0.0810, 0.0689, 0.0676, 0.0805, 0.0663, 0.0872, 0.1157,\n",
      "        0.0670, 0.0491, 0.0674, 0.0697, 0.0850, 0.1060, 0.0845, 0.0725, 0.0946,\n",
      "        0.1263, 0.0807, 0.0714, 0.0658, 0.0901, 0.0866, 0.0693, 0.0638, 0.0622,\n",
      "        0.0647, 0.0829, 0.0797, 0.0603, 0.0935, 0.0869, 0.0465, 0.1079, 0.1298,\n",
      "        0.0726, 0.0722, 0.0561, 0.0638, 0.0734, 0.1151, 0.0709, 0.0679, 0.0823,\n",
      "        0.0828, 0.0757, 0.0485, 0.1009, 0.1078, 0.0740, 0.0719, 0.0697, 0.0653,\n",
      "        0.0846, 0.0843, 0.0905, 0.0605, 0.0563, 0.0843, 0.1064, 0.0849, 0.0895,\n",
      "        0.0791, 0.0673, 0.0844, 0.1123, 0.0780, 0.0659, 0.0859, 0.0992, 0.0860,\n",
      "        0.1038, 0.0705, 0.0717, 0.1646, 0.0515, 0.0828, 0.0845, 0.0797, 0.0830,\n",
      "        0.0615, 0.0841, 0.0924, 0.0700, 0.0539, 0.0708, 0.0738, 0.0600, 0.1084,\n",
      "        0.0759, 0.0869, 0.1208, 0.0670, 0.0638, 0.0694, 0.0822, 0.0696, 0.0732,\n",
      "        0.0793, 0.0596, 0.0613, 0.0553, 0.0774, 0.0657, 0.0833, 0.1091, 0.0741,\n",
      "        0.1031, 0.0952, 0.1130, 0.0589, 0.0702, 0.1098, 0.0917, 0.0702, 0.0799,\n",
      "        0.0819, 0.0745, 0.0869, 0.0782, 0.0723, 0.0995, 0.0666, 0.0727, 0.0805,\n",
      "        0.1050, 0.0896, 0.0805, 0.0811, 0.0663, 0.0700, 0.0819, 0.0791, 0.0478,\n",
      "        0.1083, 0.0863, 0.0687, 0.0871, 0.0532, 0.0894, 0.0927, 0.0993, 0.0781,\n",
      "        0.0740, 0.0983, 0.0919, 0.0653, 0.0680, 0.0734, 0.0706, 0.1230, 0.0661,\n",
      "        0.0722, 0.0959, 0.0854, 0.0692, 0.0714, 0.0777, 0.0479, 0.0696, 0.0981,\n",
      "        0.0895, 0.0992, 0.0800, 0.0520, 0.0892, 0.1306, 0.0799, 0.0948, 0.1101,\n",
      "        0.0583, 0.0913, 0.0627, 0.0593, 0.0778, 0.0642, 0.1074, 0.1197, 0.0629,\n",
      "        0.1002, 0.0518, 0.1070, 0.0785, 0.1017, 0.0818, 0.0800, 0.1016, 0.1099,\n",
      "        0.1077, 0.1224, 0.0636, 0.0494, 0.0827, 0.1095, 0.0624, 0.0865, 0.0642,\n",
      "        0.0678, 0.0634, 0.0625, 0.1015, 0.0919, 0.0887, 0.0939, 0.0738, 0.0930,\n",
      "        0.0724, 0.0702, 0.0780, 0.0786, 0.0878, 0.0980, 0.0770, 0.0846, 0.0781,\n",
      "        0.0887, 0.0626, 0.0653, 0.0845, 0.0673, 0.0724, 0.0681, 0.0626, 0.0642,\n",
      "        0.0667, 0.0985, 0.0644, 0.0548, 0.0815, 0.1159, 0.0893, 0.0787, 0.1009,\n",
      "        0.0621, 0.0758, 0.0723, 0.0701, 0.0759, 0.1015, 0.0778, 0.0883, 0.0882,\n",
      "        0.0713, 0.0888, 0.0677, 0.0814, 0.0762, 0.0567, 0.0510, 0.0716, 0.1029,\n",
      "        0.0753, 0.0653, 0.0509, 0.1036, 0.0813, 0.0536, 0.0706, 0.1078, 0.0932,\n",
      "        0.0616, 0.0684, 0.0692, 0.0848, 0.0850, 0.1052, 0.0853, 0.0840, 0.0804,\n",
      "        0.0996, 0.0776, 0.0803, 0.0528, 0.1100, 0.0758, 0.1100, 0.0916, 0.0752,\n",
      "        0.0810, 0.0681, 0.0648, 0.0826, 0.0790, 0.0664, 0.0678, 0.0602, 0.0731,\n",
      "        0.0483, 0.0657, 0.0640, 0.0809, 0.0833, 0.0671, 0.0751, 0.0749, 0.1015,\n",
      "        0.0765, 0.0914, 0.1065, 0.0806, 0.0708, 0.0688, 0.0754, 0.0933, 0.0724,\n",
      "        0.0857, 0.1116, 0.1056, 0.0789, 0.0964, 0.1379, 0.0850, 0.0629, 0.0992,\n",
      "        0.0797, 0.1161, 0.0684, 0.0728, 0.1384, 0.0581, 0.0955, 0.0784, 0.0727,\n",
      "        0.0669, 0.0666, 0.0567, 0.0849, 0.0704, 0.1141, 0.0770, 0.0934, 0.0817,\n",
      "        0.0590, 0.0941, 0.0841, 0.0647, 0.0747, 0.0615, 0.0759, 0.0726, 0.0786,\n",
      "        0.0767, 0.0816, 0.0767, 0.0851, 0.0736, 0.0958, 0.0610, 0.1028, 0.0566,\n",
      "        0.0783, 0.0742, 0.0647, 0.0681, 0.0763, 0.0577, 0.0749, 0.0477, 0.0659,\n",
      "        0.0824, 0.0934, 0.0963, 0.1002, 0.0754, 0.0956, 0.0691, 0.0683, 0.0624,\n",
      "        0.0671, 0.0766, 0.0592, 0.0631, 0.0793, 0.0504, 0.1134, 0.0720, 0.0609,\n",
      "        0.0561, 0.0736, 0.0749, 0.0590, 0.0795, 0.0748, 0.0438, 0.1258, 0.0691,\n",
      "        0.0651, 0.0594, 0.0653, 0.0726, 0.0776, 0.0724, 0.0698, 0.0854, 0.0879,\n",
      "        0.0948, 0.0945, 0.0703, 0.0675, 0.0841, 0.0608, 0.0528, 0.0584, 0.0777,\n",
      "        0.0622, 0.0563, 0.0733, 0.1018, 0.0536, 0.0714, 0.0937, 0.1055, 0.0678,\n",
      "        0.0537, 0.0578, 0.0768, 0.1127, 0.0826, 0.0661, 0.0781, 0.0649],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(model.layer4[1].bn1.weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bR31pcuw04w7"
   },
   "source": [
    "### ReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uS62YKI306Qh"
   },
   "outputs": [],
   "source": [
    "# print(model.resnet.bn1.bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-0djCXZ3P-gQ"
   },
   "source": [
    "# Let's Try Pytorch Built in Quantization Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5WfEGw6Cm2uv"
   },
   "outputs": [],
   "source": [
    "class QuantizedModel(nn.Module):\n",
    "    def __init__(self, model_fp32):\n",
    "        super(QuantizedModel, self).__init__()\n",
    "        self.model_fp32 = model_fp32\n",
    "        self.quant = torch.quantization.QuantStub()\n",
    "        self.dequant = torch.quantization.DeQuantStub()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.quant(x)\n",
    "        x = self.model_fp32(x)\n",
    "        x = self.dequant(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 583,
     "status": "ok",
     "timestamp": 1620765984368,
     "user": {
      "displayName": "Tim Shen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgNQrJ7jwDo36WwiK5d1fd2sl5mNxpQC8UsAvxjZw=s64",
      "userId": "18284420496267004524"
     },
     "user_tz": 240
    },
    "id": "quFcQEPWyg2b",
    "outputId": "033cfe9b-13cb-4db4-ae82-0af1c69f14aa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): Identity()\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu1): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu2): ReLU(inplace=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (float_add): FloatFunctional(\n",
       "        (activation_post_process): Identity()\n",
       "      )\n",
       "      (relu3): ReLU(inplace=True)\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu1): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu2): ReLU(inplace=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (float_add): FloatFunctional(\n",
       "        (activation_post_process): Identity()\n",
       "      )\n",
       "      (relu3): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu1): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu2): ReLU(inplace=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (float_add): FloatFunctional(\n",
       "        (activation_post_process): Identity()\n",
       "      )\n",
       "      (relu3): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu1): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu2): ReLU(inplace=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (float_add): FloatFunctional(\n",
       "        (activation_post_process): Identity()\n",
       "      )\n",
       "      (relu3): ReLU(inplace=True)\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu1): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu2): ReLU(inplace=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (float_add): FloatFunctional(\n",
       "        (activation_post_process): Identity()\n",
       "      )\n",
       "      (relu3): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu1): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu2): ReLU(inplace=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (float_add): FloatFunctional(\n",
       "        (activation_post_process): Identity()\n",
       "      )\n",
       "      (relu3): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu1): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu2): ReLU(inplace=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (float_add): FloatFunctional(\n",
       "        (activation_post_process): Identity()\n",
       "      )\n",
       "      (relu3): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu1): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu2): ReLU(inplace=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (float_add): FloatFunctional(\n",
       "        (activation_post_process): Identity()\n",
       "      )\n",
       "      (relu3): ReLU(inplace=True)\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu1): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu2): ReLU(inplace=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (float_add): FloatFunctional(\n",
       "        (activation_post_process): Identity()\n",
       "      )\n",
       "      (relu3): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu1): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu2): ReLU(inplace=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (float_add): FloatFunctional(\n",
       "        (activation_post_process): Identity()\n",
       "      )\n",
       "      (relu3): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu1): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu2): ReLU(inplace=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (float_add): FloatFunctional(\n",
       "        (activation_post_process): Identity()\n",
       "      )\n",
       "      (relu3): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu1): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu2): ReLU(inplace=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (float_add): FloatFunctional(\n",
       "        (activation_post_process): Identity()\n",
       "      )\n",
       "      (relu3): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu1): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu2): ReLU(inplace=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (float_add): FloatFunctional(\n",
       "        (activation_post_process): Identity()\n",
       "      )\n",
       "      (relu3): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu1): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu2): ReLU(inplace=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (float_add): FloatFunctional(\n",
       "        (activation_post_process): Identity()\n",
       "      )\n",
       "      (relu3): ReLU(inplace=True)\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu1): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu2): ReLU(inplace=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (float_add): FloatFunctional(\n",
       "        (activation_post_process): Identity()\n",
       "      )\n",
       "      (relu3): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu1): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu2): ReLU(inplace=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (float_add): FloatFunctional(\n",
       "        (activation_post_process): Identity()\n",
       "      )\n",
       "      (relu3): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 64,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fused_model = copy.deepcopy(model)\n",
    "\n",
    "# model.eval()\n",
    "fused_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wbgTE8Mr7R_B"
   },
   "outputs": [],
   "source": [
    "# Fuse the model in place\n",
    "# model, modules_to_fuse, inplace=False\n",
    "fused_model = torch.quantization.fuse_modules(fused_model, [['conv1', 'bn1', 'relu']], inplace=True)\n",
    "\n",
    "for module_name, module in fused_model.named_children():\n",
    "    if 'layer' in module_name:\n",
    "        for basic_block_name, basic_block in module.named_children():\n",
    "            # print(basic_block_name, basic_block)\n",
    "            torch.quantization.fuse_modules(basic_block, [['conv1', 'bn1', 'relu1'], \n",
    "                                                          ['conv2', 'bn2', 'relu2'],\n",
    "                                                          ['conv3', 'bn3']], inplace=True)\n",
    "            for sub_block_name, sub_block in basic_block.named_children():\n",
    "                if sub_block_name == 'downsample':\n",
    "                    torch.quantization.fuse_modules(sub_block, [['0', '1']], inplace=True)  # cov2d + bn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Sct1XmizUs4y"
   },
   "source": [
    "## Examine Fused Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 41969,
     "status": "ok",
     "timestamp": 1620739126878,
     "user": {
      "displayName": "Tim Shen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgNQrJ7jwDo36WwiK5d1fd2sl5mNxpQC8UsAvxjZw=s64",
      "userId": "18284420496267004524"
     },
     "user_tz": 240
    },
    "id": "yYIHEmP5Uvkf",
    "outputId": "21766ec8-87d7-470e-fe1b-ca6017f6a5b1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): ConvReLU2d(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "  )\n",
      "  (bn1): Identity()\n",
      "  (relu): Identity()\n",
      "  (maxpool): Identity()\n",
      "  (layer1): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): ConvReLU2d(\n",
      "        (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): ReLU(inplace=True)\n",
      "      )\n",
      "      (bn1): Identity()\n",
      "      (relu1): Identity()\n",
      "      (conv2): ConvReLU2d(\n",
      "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): ReLU(inplace=True)\n",
      "      )\n",
      "      (bn2): Identity()\n",
      "      (relu2): Identity()\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn3): Identity()\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): Identity()\n",
      "      )\n",
      "      (float_add): FloatFunctional(\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "      (relu3): ReLU(inplace=True)\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): ConvReLU2d(\n",
      "        (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): ReLU(inplace=True)\n",
      "      )\n",
      "      (bn1): Identity()\n",
      "      (relu1): Identity()\n",
      "      (conv2): ConvReLU2d(\n",
      "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): ReLU(inplace=True)\n",
      "      )\n",
      "      (bn2): Identity()\n",
      "      (relu2): Identity()\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn3): Identity()\n",
      "      (float_add): FloatFunctional(\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "      (relu3): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): ConvReLU2d(\n",
      "        (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): ReLU(inplace=True)\n",
      "      )\n",
      "      (bn1): Identity()\n",
      "      (relu1): Identity()\n",
      "      (conv2): ConvReLU2d(\n",
      "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): ReLU(inplace=True)\n",
      "      )\n",
      "      (bn2): Identity()\n",
      "      (relu2): Identity()\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn3): Identity()\n",
      "      (float_add): FloatFunctional(\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "      (relu3): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): ConvReLU2d(\n",
      "        (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): ReLU(inplace=True)\n",
      "      )\n",
      "      (bn1): Identity()\n",
      "      (relu1): Identity()\n",
      "      (conv2): ConvReLU2d(\n",
      "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "        (1): ReLU(inplace=True)\n",
      "      )\n",
      "      (bn2): Identity()\n",
      "      (relu2): Identity()\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn3): Identity()\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2))\n",
      "        (1): Identity()\n",
      "      )\n",
      "      (float_add): FloatFunctional(\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "      (relu3): ReLU(inplace=True)\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): ConvReLU2d(\n",
      "        (0): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): ReLU(inplace=True)\n",
      "      )\n",
      "      (bn1): Identity()\n",
      "      (relu1): Identity()\n",
      "      (conv2): ConvReLU2d(\n",
      "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): ReLU(inplace=True)\n",
      "      )\n",
      "      (bn2): Identity()\n",
      "      (relu2): Identity()\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn3): Identity()\n",
      "      (float_add): FloatFunctional(\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "      (relu3): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): ConvReLU2d(\n",
      "        (0): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): ReLU(inplace=True)\n",
      "      )\n",
      "      (bn1): Identity()\n",
      "      (relu1): Identity()\n",
      "      (conv2): ConvReLU2d(\n",
      "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): ReLU(inplace=True)\n",
      "      )\n",
      "      (bn2): Identity()\n",
      "      (relu2): Identity()\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn3): Identity()\n",
      "      (float_add): FloatFunctional(\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "      (relu3): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): ConvReLU2d(\n",
      "        (0): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): ReLU(inplace=True)\n",
      "      )\n",
      "      (bn1): Identity()\n",
      "      (relu1): Identity()\n",
      "      (conv2): ConvReLU2d(\n",
      "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): ReLU(inplace=True)\n",
      "      )\n",
      "      (bn2): Identity()\n",
      "      (relu2): Identity()\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn3): Identity()\n",
      "      (float_add): FloatFunctional(\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "      (relu3): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): ConvReLU2d(\n",
      "        (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): ReLU(inplace=True)\n",
      "      )\n",
      "      (bn1): Identity()\n",
      "      (relu1): Identity()\n",
      "      (conv2): ConvReLU2d(\n",
      "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "        (1): ReLU(inplace=True)\n",
      "      )\n",
      "      (bn2): Identity()\n",
      "      (relu2): Identity()\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn3): Identity()\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2))\n",
      "        (1): Identity()\n",
      "      )\n",
      "      (float_add): FloatFunctional(\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "      (relu3): ReLU(inplace=True)\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): ConvReLU2d(\n",
      "        (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): ReLU(inplace=True)\n",
      "      )\n",
      "      (bn1): Identity()\n",
      "      (relu1): Identity()\n",
      "      (conv2): ConvReLU2d(\n",
      "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): ReLU(inplace=True)\n",
      "      )\n",
      "      (bn2): Identity()\n",
      "      (relu2): Identity()\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn3): Identity()\n",
      "      (float_add): FloatFunctional(\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "      (relu3): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): ConvReLU2d(\n",
      "        (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): ReLU(inplace=True)\n",
      "      )\n",
      "      (bn1): Identity()\n",
      "      (relu1): Identity()\n",
      "      (conv2): ConvReLU2d(\n",
      "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): ReLU(inplace=True)\n",
      "      )\n",
      "      (bn2): Identity()\n",
      "      (relu2): Identity()\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn3): Identity()\n",
      "      (float_add): FloatFunctional(\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "      (relu3): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): ConvReLU2d(\n",
      "        (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): ReLU(inplace=True)\n",
      "      )\n",
      "      (bn1): Identity()\n",
      "      (relu1): Identity()\n",
      "      (conv2): ConvReLU2d(\n",
      "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): ReLU(inplace=True)\n",
      "      )\n",
      "      (bn2): Identity()\n",
      "      (relu2): Identity()\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn3): Identity()\n",
      "      (float_add): FloatFunctional(\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "      (relu3): ReLU(inplace=True)\n",
      "    )\n",
      "    (4): Bottleneck(\n",
      "      (conv1): ConvReLU2d(\n",
      "        (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): ReLU(inplace=True)\n",
      "      )\n",
      "      (bn1): Identity()\n",
      "      (relu1): Identity()\n",
      "      (conv2): ConvReLU2d(\n",
      "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): ReLU(inplace=True)\n",
      "      )\n",
      "      (bn2): Identity()\n",
      "      (relu2): Identity()\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn3): Identity()\n",
      "      (float_add): FloatFunctional(\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "      (relu3): ReLU(inplace=True)\n",
      "    )\n",
      "    (5): Bottleneck(\n",
      "      (conv1): ConvReLU2d(\n",
      "        (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): ReLU(inplace=True)\n",
      "      )\n",
      "      (bn1): Identity()\n",
      "      (relu1): Identity()\n",
      "      (conv2): ConvReLU2d(\n",
      "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): ReLU(inplace=True)\n",
      "      )\n",
      "      (bn2): Identity()\n",
      "      (relu2): Identity()\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn3): Identity()\n",
      "      (float_add): FloatFunctional(\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "      (relu3): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): ConvReLU2d(\n",
      "        (0): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): ReLU(inplace=True)\n",
      "      )\n",
      "      (bn1): Identity()\n",
      "      (relu1): Identity()\n",
      "      (conv2): ConvReLU2d(\n",
      "        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "        (1): ReLU(inplace=True)\n",
      "      )\n",
      "      (bn2): Identity()\n",
      "      (relu2): Identity()\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn3): Identity()\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2))\n",
      "        (1): Identity()\n",
      "      )\n",
      "      (float_add): FloatFunctional(\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "      (relu3): ReLU(inplace=True)\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): ConvReLU2d(\n",
      "        (0): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): ReLU(inplace=True)\n",
      "      )\n",
      "      (bn1): Identity()\n",
      "      (relu1): Identity()\n",
      "      (conv2): ConvReLU2d(\n",
      "        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): ReLU(inplace=True)\n",
      "      )\n",
      "      (bn2): Identity()\n",
      "      (relu2): Identity()\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn3): Identity()\n",
      "      (float_add): FloatFunctional(\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "      (relu3): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): ConvReLU2d(\n",
      "        (0): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): ReLU(inplace=True)\n",
      "      )\n",
      "      (bn1): Identity()\n",
      "      (relu1): Identity()\n",
      "      (conv2): ConvReLU2d(\n",
      "        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): ReLU(inplace=True)\n",
      "      )\n",
      "      (bn2): Identity()\n",
      "      (relu2): Identity()\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (bn3): Identity()\n",
      "      (float_add): FloatFunctional(\n",
      "        (activation_post_process): Identity()\n",
      "      )\n",
      "      (relu3): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(fused_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YLEAVIXWVPf2"
   },
   "outputs": [],
   "source": [
    "# torch.save(fused_model.state_dict(), savepath + 'fused.pt')\n",
    "# torch.jit.save(torch.jit.script(fused_model), savepath + 'fused_jit.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uxDFnux67OFU"
   },
   "outputs": [],
   "source": [
    "# Prepare the model for static quantization. \n",
    "# This inserts observers in the model that will observe activation tensors during calibration.\n",
    "quantized_model = QuantizedModel(model_fp32=fused_model)\n",
    "\n",
    "# config\n",
    "quantization_config = torch.quantization.get_default_qconfig('fbgemm')  # x86\n",
    "# quantization_config = torch.quantization.default_qconfig\n",
    "# quantization_config = torch.quantization.QConfig(\n",
    "#     activation=torch.quantization.MinMaxObserver.with_args(dtype=torch.quint8), \n",
    "#     weight=torch.quantization.MinMaxObserver.with_args(\n",
    "#         dtype=torch.qint8, \n",
    "#         qscheme=torch.per_tensor_symmetric))\n",
    "\n",
    "quantized_model.qconfig = quantization_config\n",
    "# print(quantized_model.qconfig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3nSQJiR1rvXD"
   },
   "source": [
    "## Examine Model before Calibration\n",
    "\n",
    "https://pytorch.org/docs/stable/_modules/torch/quantization/quantize.html#prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 261,
     "status": "ok",
     "timestamp": 1620766012486,
     "user": {
      "displayName": "Tim Shen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgNQrJ7jwDo36WwiK5d1fd2sl5mNxpQC8UsAvxjZw=s64",
      "userId": "18284420496267004524"
     },
     "user_tz": 240
    },
    "id": "uTZNSNPGkv0-",
    "outputId": "1445aa2d-3c26-4d12-ea05-221bc96ad627"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/torch/quantization/observer.py:123: UserWarning: Please use quant_min and quant_max to specify the range for observers.                     reduce_range will be deprecated in a future release of PyTorch.\n",
      "  reduce_range will be deprecated in a future release of PyTorch.\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "QuantizedModel(\n",
       "  (model_fp32): ResNet(\n",
       "    (conv1): ConvReLU2d(\n",
       "      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): ReLU(inplace=True)\n",
       "      (activation_post_process): HistogramObserver()\n",
       "    )\n",
       "    (bn1): Identity()\n",
       "    (relu): Identity()\n",
       "    (maxpool): Identity()\n",
       "    (layer1): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): ConvReLU2d(\n",
       "          (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): ReLU(inplace=True)\n",
       "          (activation_post_process): HistogramObserver()\n",
       "        )\n",
       "        (bn1): Identity()\n",
       "        (relu1): Identity()\n",
       "        (conv2): ConvReLU2d(\n",
       "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU(inplace=True)\n",
       "          (activation_post_process): HistogramObserver()\n",
       "        )\n",
       "        (bn2): Identity()\n",
       "        (relu2): Identity()\n",
       "        (conv3): Conv2d(\n",
       "          64, 256, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (activation_post_process): HistogramObserver()\n",
       "        )\n",
       "        (bn3): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(\n",
       "            64, 256, kernel_size=(1, 1), stride=(1, 1)\n",
       "            (activation_post_process): HistogramObserver()\n",
       "          )\n",
       "          (1): Identity()\n",
       "        )\n",
       "        (float_add): FloatFunctional(\n",
       "          (activation_post_process): HistogramObserver()\n",
       "        )\n",
       "        (relu3): ReLU(inplace=True)\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): ConvReLU2d(\n",
       "          (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): ReLU(inplace=True)\n",
       "          (activation_post_process): HistogramObserver()\n",
       "        )\n",
       "        (bn1): Identity()\n",
       "        (relu1): Identity()\n",
       "        (conv2): ConvReLU2d(\n",
       "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU(inplace=True)\n",
       "          (activation_post_process): HistogramObserver()\n",
       "        )\n",
       "        (bn2): Identity()\n",
       "        (relu2): Identity()\n",
       "        (conv3): Conv2d(\n",
       "          64, 256, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (activation_post_process): HistogramObserver()\n",
       "        )\n",
       "        (bn3): Identity()\n",
       "        (float_add): FloatFunctional(\n",
       "          (activation_post_process): HistogramObserver()\n",
       "        )\n",
       "        (relu3): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): ConvReLU2d(\n",
       "          (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): ReLU(inplace=True)\n",
       "          (activation_post_process): HistogramObserver()\n",
       "        )\n",
       "        (bn1): Identity()\n",
       "        (relu1): Identity()\n",
       "        (conv2): ConvReLU2d(\n",
       "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU(inplace=True)\n",
       "          (activation_post_process): HistogramObserver()\n",
       "        )\n",
       "        (bn2): Identity()\n",
       "        (relu2): Identity()\n",
       "        (conv3): Conv2d(\n",
       "          64, 256, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (activation_post_process): HistogramObserver()\n",
       "        )\n",
       "        (bn3): Identity()\n",
       "        (float_add): FloatFunctional(\n",
       "          (activation_post_process): HistogramObserver()\n",
       "        )\n",
       "        (relu3): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): ConvReLU2d(\n",
       "          (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): ReLU(inplace=True)\n",
       "          (activation_post_process): HistogramObserver()\n",
       "        )\n",
       "        (bn1): Identity()\n",
       "        (relu1): Identity()\n",
       "        (conv2): ConvReLU2d(\n",
       "          (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "          (1): ReLU(inplace=True)\n",
       "          (activation_post_process): HistogramObserver()\n",
       "        )\n",
       "        (bn2): Identity()\n",
       "        (relu2): Identity()\n",
       "        (conv3): Conv2d(\n",
       "          128, 512, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (activation_post_process): HistogramObserver()\n",
       "        )\n",
       "        (bn3): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(\n",
       "            256, 512, kernel_size=(1, 1), stride=(2, 2)\n",
       "            (activation_post_process): HistogramObserver()\n",
       "          )\n",
       "          (1): Identity()\n",
       "        )\n",
       "        (float_add): FloatFunctional(\n",
       "          (activation_post_process): HistogramObserver()\n",
       "        )\n",
       "        (relu3): ReLU(inplace=True)\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): ConvReLU2d(\n",
       "          (0): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): ReLU(inplace=True)\n",
       "          (activation_post_process): HistogramObserver()\n",
       "        )\n",
       "        (bn1): Identity()\n",
       "        (relu1): Identity()\n",
       "        (conv2): ConvReLU2d(\n",
       "          (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU(inplace=True)\n",
       "          (activation_post_process): HistogramObserver()\n",
       "        )\n",
       "        (bn2): Identity()\n",
       "        (relu2): Identity()\n",
       "        (conv3): Conv2d(\n",
       "          128, 512, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (activation_post_process): HistogramObserver()\n",
       "        )\n",
       "        (bn3): Identity()\n",
       "        (float_add): FloatFunctional(\n",
       "          (activation_post_process): HistogramObserver()\n",
       "        )\n",
       "        (relu3): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): ConvReLU2d(\n",
       "          (0): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): ReLU(inplace=True)\n",
       "          (activation_post_process): HistogramObserver()\n",
       "        )\n",
       "        (bn1): Identity()\n",
       "        (relu1): Identity()\n",
       "        (conv2): ConvReLU2d(\n",
       "          (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU(inplace=True)\n",
       "          (activation_post_process): HistogramObserver()\n",
       "        )\n",
       "        (bn2): Identity()\n",
       "        (relu2): Identity()\n",
       "        (conv3): Conv2d(\n",
       "          128, 512, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (activation_post_process): HistogramObserver()\n",
       "        )\n",
       "        (bn3): Identity()\n",
       "        (float_add): FloatFunctional(\n",
       "          (activation_post_process): HistogramObserver()\n",
       "        )\n",
       "        (relu3): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): ConvReLU2d(\n",
       "          (0): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): ReLU(inplace=True)\n",
       "          (activation_post_process): HistogramObserver()\n",
       "        )\n",
       "        (bn1): Identity()\n",
       "        (relu1): Identity()\n",
       "        (conv2): ConvReLU2d(\n",
       "          (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU(inplace=True)\n",
       "          (activation_post_process): HistogramObserver()\n",
       "        )\n",
       "        (bn2): Identity()\n",
       "        (relu2): Identity()\n",
       "        (conv3): Conv2d(\n",
       "          128, 512, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (activation_post_process): HistogramObserver()\n",
       "        )\n",
       "        (bn3): Identity()\n",
       "        (float_add): FloatFunctional(\n",
       "          (activation_post_process): HistogramObserver()\n",
       "        )\n",
       "        (relu3): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): ConvReLU2d(\n",
       "          (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): ReLU(inplace=True)\n",
       "          (activation_post_process): HistogramObserver()\n",
       "        )\n",
       "        (bn1): Identity()\n",
       "        (relu1): Identity()\n",
       "        (conv2): ConvReLU2d(\n",
       "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "          (1): ReLU(inplace=True)\n",
       "          (activation_post_process): HistogramObserver()\n",
       "        )\n",
       "        (bn2): Identity()\n",
       "        (relu2): Identity()\n",
       "        (conv3): Conv2d(\n",
       "          256, 1024, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (activation_post_process): HistogramObserver()\n",
       "        )\n",
       "        (bn3): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(\n",
       "            512, 1024, kernel_size=(1, 1), stride=(2, 2)\n",
       "            (activation_post_process): HistogramObserver()\n",
       "          )\n",
       "          (1): Identity()\n",
       "        )\n",
       "        (float_add): FloatFunctional(\n",
       "          (activation_post_process): HistogramObserver()\n",
       "        )\n",
       "        (relu3): ReLU(inplace=True)\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): ConvReLU2d(\n",
       "          (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): ReLU(inplace=True)\n",
       "          (activation_post_process): HistogramObserver()\n",
       "        )\n",
       "        (bn1): Identity()\n",
       "        (relu1): Identity()\n",
       "        (conv2): ConvReLU2d(\n",
       "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU(inplace=True)\n",
       "          (activation_post_process): HistogramObserver()\n",
       "        )\n",
       "        (bn2): Identity()\n",
       "        (relu2): Identity()\n",
       "        (conv3): Conv2d(\n",
       "          256, 1024, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (activation_post_process): HistogramObserver()\n",
       "        )\n",
       "        (bn3): Identity()\n",
       "        (float_add): FloatFunctional(\n",
       "          (activation_post_process): HistogramObserver()\n",
       "        )\n",
       "        (relu3): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): ConvReLU2d(\n",
       "          (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): ReLU(inplace=True)\n",
       "          (activation_post_process): HistogramObserver()\n",
       "        )\n",
       "        (bn1): Identity()\n",
       "        (relu1): Identity()\n",
       "        (conv2): ConvReLU2d(\n",
       "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU(inplace=True)\n",
       "          (activation_post_process): HistogramObserver()\n",
       "        )\n",
       "        (bn2): Identity()\n",
       "        (relu2): Identity()\n",
       "        (conv3): Conv2d(\n",
       "          256, 1024, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (activation_post_process): HistogramObserver()\n",
       "        )\n",
       "        (bn3): Identity()\n",
       "        (float_add): FloatFunctional(\n",
       "          (activation_post_process): HistogramObserver()\n",
       "        )\n",
       "        (relu3): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): ConvReLU2d(\n",
       "          (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): ReLU(inplace=True)\n",
       "          (activation_post_process): HistogramObserver()\n",
       "        )\n",
       "        (bn1): Identity()\n",
       "        (relu1): Identity()\n",
       "        (conv2): ConvReLU2d(\n",
       "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU(inplace=True)\n",
       "          (activation_post_process): HistogramObserver()\n",
       "        )\n",
       "        (bn2): Identity()\n",
       "        (relu2): Identity()\n",
       "        (conv3): Conv2d(\n",
       "          256, 1024, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (activation_post_process): HistogramObserver()\n",
       "        )\n",
       "        (bn3): Identity()\n",
       "        (float_add): FloatFunctional(\n",
       "          (activation_post_process): HistogramObserver()\n",
       "        )\n",
       "        (relu3): ReLU(inplace=True)\n",
       "      )\n",
       "      (4): Bottleneck(\n",
       "        (conv1): ConvReLU2d(\n",
       "          (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): ReLU(inplace=True)\n",
       "          (activation_post_process): HistogramObserver()\n",
       "        )\n",
       "        (bn1): Identity()\n",
       "        (relu1): Identity()\n",
       "        (conv2): ConvReLU2d(\n",
       "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU(inplace=True)\n",
       "          (activation_post_process): HistogramObserver()\n",
       "        )\n",
       "        (bn2): Identity()\n",
       "        (relu2): Identity()\n",
       "        (conv3): Conv2d(\n",
       "          256, 1024, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (activation_post_process): HistogramObserver()\n",
       "        )\n",
       "        (bn3): Identity()\n",
       "        (float_add): FloatFunctional(\n",
       "          (activation_post_process): HistogramObserver()\n",
       "        )\n",
       "        (relu3): ReLU(inplace=True)\n",
       "      )\n",
       "      (5): Bottleneck(\n",
       "        (conv1): ConvReLU2d(\n",
       "          (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): ReLU(inplace=True)\n",
       "          (activation_post_process): HistogramObserver()\n",
       "        )\n",
       "        (bn1): Identity()\n",
       "        (relu1): Identity()\n",
       "        (conv2): ConvReLU2d(\n",
       "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU(inplace=True)\n",
       "          (activation_post_process): HistogramObserver()\n",
       "        )\n",
       "        (bn2): Identity()\n",
       "        (relu2): Identity()\n",
       "        (conv3): Conv2d(\n",
       "          256, 1024, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (activation_post_process): HistogramObserver()\n",
       "        )\n",
       "        (bn3): Identity()\n",
       "        (float_add): FloatFunctional(\n",
       "          (activation_post_process): HistogramObserver()\n",
       "        )\n",
       "        (relu3): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): ConvReLU2d(\n",
       "          (0): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): ReLU(inplace=True)\n",
       "          (activation_post_process): HistogramObserver()\n",
       "        )\n",
       "        (bn1): Identity()\n",
       "        (relu1): Identity()\n",
       "        (conv2): ConvReLU2d(\n",
       "          (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "          (1): ReLU(inplace=True)\n",
       "          (activation_post_process): HistogramObserver()\n",
       "        )\n",
       "        (bn2): Identity()\n",
       "        (relu2): Identity()\n",
       "        (conv3): Conv2d(\n",
       "          512, 2048, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (activation_post_process): HistogramObserver()\n",
       "        )\n",
       "        (bn3): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(\n",
       "            1024, 2048, kernel_size=(1, 1), stride=(2, 2)\n",
       "            (activation_post_process): HistogramObserver()\n",
       "          )\n",
       "          (1): Identity()\n",
       "        )\n",
       "        (float_add): FloatFunctional(\n",
       "          (activation_post_process): HistogramObserver()\n",
       "        )\n",
       "        (relu3): ReLU(inplace=True)\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): ConvReLU2d(\n",
       "          (0): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): ReLU(inplace=True)\n",
       "          (activation_post_process): HistogramObserver()\n",
       "        )\n",
       "        (bn1): Identity()\n",
       "        (relu1): Identity()\n",
       "        (conv2): ConvReLU2d(\n",
       "          (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU(inplace=True)\n",
       "          (activation_post_process): HistogramObserver()\n",
       "        )\n",
       "        (bn2): Identity()\n",
       "        (relu2): Identity()\n",
       "        (conv3): Conv2d(\n",
       "          512, 2048, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (activation_post_process): HistogramObserver()\n",
       "        )\n",
       "        (bn3): Identity()\n",
       "        (float_add): FloatFunctional(\n",
       "          (activation_post_process): HistogramObserver()\n",
       "        )\n",
       "        (relu3): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): ConvReLU2d(\n",
       "          (0): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): ReLU(inplace=True)\n",
       "          (activation_post_process): HistogramObserver()\n",
       "        )\n",
       "        (bn1): Identity()\n",
       "        (relu1): Identity()\n",
       "        (conv2): ConvReLU2d(\n",
       "          (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU(inplace=True)\n",
       "          (activation_post_process): HistogramObserver()\n",
       "        )\n",
       "        (bn2): Identity()\n",
       "        (relu2): Identity()\n",
       "        (conv3): Conv2d(\n",
       "          512, 2048, kernel_size=(1, 1), stride=(1, 1)\n",
       "          (activation_post_process): HistogramObserver()\n",
       "        )\n",
       "        (bn3): Identity()\n",
       "        (float_add): FloatFunctional(\n",
       "          (activation_post_process): HistogramObserver()\n",
       "        )\n",
       "        (relu3): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(\n",
       "      in_features=2048, out_features=1000, bias=True\n",
       "      (activation_post_process): HistogramObserver()\n",
       "    )\n",
       "  )\n",
       "  (quant): QuantStub(\n",
       "    (activation_post_process): HistogramObserver()\n",
       "  )\n",
       "  (dequant): DeQuantStub()\n",
       ")"
      ]
     },
     "execution_count": 67,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prepare the model for static quantization\n",
    "torch.quantization.prepare(quantized_model, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3C0TZHJMllcL"
   },
   "source": [
    "## Calibration and Convert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RRQY57A_3kpU"
   },
   "outputs": [],
   "source": [
    "# Calibration!!!\n",
    "# quantized_model.eval()\n",
    "# for batch, target in test_loader:\n",
    "# \tmodel(batch)\n",
    "\n",
    "# calibrate_model(model=quantized_model, loader=test_loader)\n",
    "calibrate_model_n_liter(model=quantized_model, loader=test_loader, count=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4Qz1b_iPEtk-"
   },
   "outputs": [],
   "source": [
    "# print(quantized_model.model_fp32.conv1)\n",
    "# torch.save(quantized_model.state_dict(), savepath + 'temp.pt'.format())\n",
    "\n",
    "# RuntimeError: Hook '_observer_forward_hook' on module 'ConvReLU2d' expected the input argument to be typed as a Tuple but found type: 'Tensor' instead.\n",
    "# This error occured while scripting the forward hook '_observer_forward_hook' on module ConvReLU2d. \n",
    "# If you did not want to script this hook remove it from the original NN module before scripting. \n",
    "# This hook was expected to have the following signature: _observer_forward_hook(self, input: Tuple[Tensor], output: Tensor). \n",
    "# The type of the output arg is the returned type from either the forward method or the previous hook if it exists. Note that hooks can return anything, but if the hook is on a submodule the outer module is expecting the same return type as the submodule's forward.\n",
    "# torch.jit.save(torch.jit.script(quantized_model), savepath + 'temp_jit.pt'.format())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2124,
     "status": "ok",
     "timestamp": 1620766065670,
     "user": {
      "displayName": "Tim Shen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgNQrJ7jwDo36WwiK5d1fd2sl5mNxpQC8UsAvxjZw=s64",
      "userId": "18284420496267004524"
     },
     "user_tz": 240
    },
    "id": "UwUX8XmkjtRs",
    "outputId": "b38a1675-6016-4a40-f263-9d3737fdd3d7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "QuantizedModel(\n",
       "  (model_fp32): ResNet(\n",
       "    (conv1): QuantizedConvReLU2d(3, 64, kernel_size=(3, 3), stride=(1, 1), scale=0.01995701715350151, zero_point=0, padding=(1, 1))\n",
       "    (bn1): Identity()\n",
       "    (relu): Identity()\n",
       "    (maxpool): Identity()\n",
       "    (layer1): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): QuantizedConvReLU2d(64, 64, kernel_size=(1, 1), stride=(1, 1), scale=0.012247094884514809, zero_point=0)\n",
       "        (bn1): Identity()\n",
       "        (relu1): Identity()\n",
       "        (conv2): QuantizedConvReLU2d(64, 64, kernel_size=(3, 3), stride=(1, 1), scale=0.015170135535299778, zero_point=0, padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (relu2): Identity()\n",
       "        (conv3): QuantizedConv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), scale=0.021831415593624115, zero_point=71)\n",
       "        (bn3): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): QuantizedConv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), scale=0.024291105568408966, zero_point=79)\n",
       "          (1): Identity()\n",
       "        )\n",
       "        (float_add): QFunctional(\n",
       "          scale=0.037882883101701736, zero_point=64\n",
       "          (activation_post_process): Identity()\n",
       "        )\n",
       "        (relu3): ReLU(inplace=True)\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): QuantizedConvReLU2d(256, 64, kernel_size=(1, 1), stride=(1, 1), scale=0.008946525864303112, zero_point=0)\n",
       "        (bn1): Identity()\n",
       "        (relu1): Identity()\n",
       "        (conv2): QuantizedConvReLU2d(64, 64, kernel_size=(3, 3), stride=(1, 1), scale=0.007112463936209679, zero_point=0, padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (relu2): Identity()\n",
       "        (conv3): QuantizedConv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), scale=0.00766779063269496, zero_point=70)\n",
       "        (bn3): Identity()\n",
       "        (float_add): QFunctional(\n",
       "          scale=0.021351592615246773, zero_point=39\n",
       "          (activation_post_process): Identity()\n",
       "        )\n",
       "        (relu3): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): QuantizedConvReLU2d(256, 64, kernel_size=(1, 1), stride=(1, 1), scale=0.00778568210080266, zero_point=0)\n",
       "        (bn1): Identity()\n",
       "        (relu1): Identity()\n",
       "        (conv2): QuantizedConvReLU2d(64, 64, kernel_size=(3, 3), stride=(1, 1), scale=0.006896554958075285, zero_point=0, padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (relu2): Identity()\n",
       "        (conv3): QuantizedConv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), scale=0.010948924347758293, zero_point=46)\n",
       "        (bn3): Identity()\n",
       "        (float_add): QFunctional(\n",
       "          scale=0.02160254493355751, zero_point=28\n",
       "          (activation_post_process): Identity()\n",
       "        )\n",
       "        (relu3): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): QuantizedConvReLU2d(256, 128, kernel_size=(1, 1), stride=(1, 1), scale=0.011036984622478485, zero_point=0)\n",
       "        (bn1): Identity()\n",
       "        (relu1): Identity()\n",
       "        (conv2): QuantizedConvReLU2d(128, 128, kernel_size=(3, 3), stride=(2, 2), scale=0.013369028456509113, zero_point=0, padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (relu2): Identity()\n",
       "        (conv3): QuantizedConv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), scale=0.022531753405928612, zero_point=62)\n",
       "        (bn3): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): QuantizedConv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), scale=0.025517484173178673, zero_point=64)\n",
       "          (1): Identity()\n",
       "        )\n",
       "        (float_add): QFunctional(\n",
       "          scale=0.026159850880503654, zero_point=54\n",
       "          (activation_post_process): Identity()\n",
       "        )\n",
       "        (relu3): ReLU(inplace=True)\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): QuantizedConvReLU2d(512, 128, kernel_size=(1, 1), stride=(1, 1), scale=0.0055076610296964645, zero_point=0)\n",
       "        (bn1): Identity()\n",
       "        (relu1): Identity()\n",
       "        (conv2): QuantizedConvReLU2d(128, 128, kernel_size=(3, 3), stride=(1, 1), scale=0.006651518400758505, zero_point=0, padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (relu2): Identity()\n",
       "        (conv3): QuantizedConv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), scale=0.015302378684282303, zero_point=58)\n",
       "        (bn3): Identity()\n",
       "        (float_add): QFunctional(\n",
       "          scale=0.021668151021003723, zero_point=40\n",
       "          (activation_post_process): Identity()\n",
       "        )\n",
       "        (relu3): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): QuantizedConvReLU2d(512, 128, kernel_size=(1, 1), stride=(1, 1), scale=0.012084526009857655, zero_point=0)\n",
       "        (bn1): Identity()\n",
       "        (relu1): Identity()\n",
       "        (conv2): QuantizedConvReLU2d(128, 128, kernel_size=(3, 3), stride=(1, 1), scale=0.012848811224102974, zero_point=0, padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (relu2): Identity()\n",
       "        (conv3): QuantizedConv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), scale=0.01717478036880493, zero_point=66)\n",
       "        (bn3): Identity()\n",
       "        (float_add): QFunctional(\n",
       "          scale=0.02450917288661003, zero_point=49\n",
       "          (activation_post_process): Identity()\n",
       "        )\n",
       "        (relu3): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): QuantizedConvReLU2d(512, 128, kernel_size=(1, 1), stride=(1, 1), scale=0.00784199871122837, zero_point=0)\n",
       "        (bn1): Identity()\n",
       "        (relu1): Identity()\n",
       "        (conv2): QuantizedConvReLU2d(128, 128, kernel_size=(3, 3), stride=(1, 1), scale=0.009989307262003422, zero_point=0, padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (relu2): Identity()\n",
       "        (conv3): QuantizedConv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), scale=0.015956006944179535, zero_point=52)\n",
       "        (bn3): Identity()\n",
       "        (float_add): QFunctional(\n",
       "          scale=0.022397495806217194, zero_point=39\n",
       "          (activation_post_process): Identity()\n",
       "        )\n",
       "        (relu3): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): QuantizedConvReLU2d(512, 256, kernel_size=(1, 1), stride=(1, 1), scale=0.012226011604070663, zero_point=0)\n",
       "        (bn1): Identity()\n",
       "        (relu1): Identity()\n",
       "        (conv2): QuantizedConvReLU2d(256, 256, kernel_size=(3, 3), stride=(2, 2), scale=0.008156905882060528, zero_point=0, padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (relu2): Identity()\n",
       "        (conv3): QuantizedConv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), scale=0.012732096947729588, zero_point=60)\n",
       "        (bn3): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): QuantizedConv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), scale=0.02072960138320923, zero_point=46)\n",
       "          (1): Identity()\n",
       "        )\n",
       "        (float_add): QFunctional(\n",
       "          scale=0.021204598248004913, zero_point=63\n",
       "          (activation_post_process): Identity()\n",
       "        )\n",
       "        (relu3): ReLU(inplace=True)\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): QuantizedConvReLU2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), scale=0.006450335029512644, zero_point=0)\n",
       "        (bn1): Identity()\n",
       "        (relu1): Identity()\n",
       "        (conv2): QuantizedConvReLU2d(256, 256, kernel_size=(3, 3), stride=(1, 1), scale=0.005743715446442366, zero_point=0, padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (relu2): Identity()\n",
       "        (conv3): QuantizedConv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), scale=0.009538553655147552, zero_point=64)\n",
       "        (bn3): Identity()\n",
       "        (float_add): QFunctional(\n",
       "          scale=0.020414425060153008, zero_point=38\n",
       "          (activation_post_process): Identity()\n",
       "        )\n",
       "        (relu3): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): QuantizedConvReLU2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), scale=0.005065525881946087, zero_point=0)\n",
       "        (bn1): Identity()\n",
       "        (relu1): Identity()\n",
       "        (conv2): QuantizedConvReLU2d(256, 256, kernel_size=(3, 3), stride=(1, 1), scale=0.00478981900960207, zero_point=0, padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (relu2): Identity()\n",
       "        (conv3): QuantizedConv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), scale=0.007929501123726368, zero_point=65)\n",
       "        (bn3): Identity()\n",
       "        (float_add): QFunctional(\n",
       "          scale=0.018458731472492218, zero_point=39\n",
       "          (activation_post_process): Identity()\n",
       "        )\n",
       "        (relu3): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): QuantizedConvReLU2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), scale=0.0057390788570046425, zero_point=0)\n",
       "        (bn1): Identity()\n",
       "        (relu1): Identity()\n",
       "        (conv2): QuantizedConvReLU2d(256, 256, kernel_size=(3, 3), stride=(1, 1), scale=0.0047314888797700405, zero_point=0, padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (relu2): Identity()\n",
       "        (conv3): QuantizedConv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), scale=0.011108535341918468, zero_point=85)\n",
       "        (bn3): Identity()\n",
       "        (float_add): QFunctional(\n",
       "          scale=0.021302862092852592, zero_point=40\n",
       "          (activation_post_process): Identity()\n",
       "        )\n",
       "        (relu3): ReLU(inplace=True)\n",
       "      )\n",
       "      (4): Bottleneck(\n",
       "        (conv1): QuantizedConvReLU2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), scale=0.006864129565656185, zero_point=0)\n",
       "        (bn1): Identity()\n",
       "        (relu1): Identity()\n",
       "        (conv2): QuantizedConvReLU2d(256, 256, kernel_size=(3, 3), stride=(1, 1), scale=0.006136487703770399, zero_point=0, padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (relu2): Identity()\n",
       "        (conv3): QuantizedConv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), scale=0.012032756581902504, zero_point=66)\n",
       "        (bn3): Identity()\n",
       "        (float_add): QFunctional(\n",
       "          scale=0.021669287234544754, zero_point=37\n",
       "          (activation_post_process): Identity()\n",
       "        )\n",
       "        (relu3): ReLU(inplace=True)\n",
       "      )\n",
       "      (5): Bottleneck(\n",
       "        (conv1): QuantizedConvReLU2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), scale=0.0096104322001338, zero_point=0)\n",
       "        (bn1): Identity()\n",
       "        (relu1): Identity()\n",
       "        (conv2): QuantizedConvReLU2d(256, 256, kernel_size=(3, 3), stride=(1, 1), scale=0.00886958185583353, zero_point=0, padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (relu2): Identity()\n",
       "        (conv3): QuantizedConv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), scale=0.015868769958615303, zero_point=59)\n",
       "        (bn3): Identity()\n",
       "        (float_add): QFunctional(\n",
       "          scale=0.024337753653526306, zero_point=38\n",
       "          (activation_post_process): Identity()\n",
       "        )\n",
       "        (relu3): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): QuantizedConvReLU2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), scale=0.00999458972364664, zero_point=0)\n",
       "        (bn1): Identity()\n",
       "        (relu1): Identity()\n",
       "        (conv2): QuantizedConvReLU2d(512, 512, kernel_size=(3, 3), stride=(2, 2), scale=0.010501925833523273, zero_point=0, padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (relu2): Identity()\n",
       "        (conv3): QuantizedConv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), scale=0.019576339051127434, zero_point=45)\n",
       "        (bn3): Identity()\n",
       "        (downsample): Sequential(\n",
       "          (0): QuantizedConv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), scale=0.013569620437920094, zero_point=61)\n",
       "          (1): Identity()\n",
       "        )\n",
       "        (float_add): QFunctional(\n",
       "          scale=0.022279461845755577, zero_point=51\n",
       "          (activation_post_process): Identity()\n",
       "        )\n",
       "        (relu3): ReLU(inplace=True)\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): QuantizedConvReLU2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), scale=0.005735202692449093, zero_point=0)\n",
       "        (bn1): Identity()\n",
       "        (relu1): Identity()\n",
       "        (conv2): QuantizedConvReLU2d(512, 512, kernel_size=(3, 3), stride=(1, 1), scale=0.0051817502826452255, zero_point=0, padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (relu2): Identity()\n",
       "        (conv3): QuantizedConv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), scale=0.009322688914835453, zero_point=62)\n",
       "        (bn3): Identity()\n",
       "        (float_add): QFunctional(\n",
       "          scale=0.024104125797748566, zero_point=36\n",
       "          (activation_post_process): Identity()\n",
       "        )\n",
       "        (relu3): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): QuantizedConvReLU2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), scale=0.007428400684148073, zero_point=0)\n",
       "        (bn1): Identity()\n",
       "        (relu1): Identity()\n",
       "        (conv2): QuantizedConvReLU2d(512, 512, kernel_size=(3, 3), stride=(1, 1), scale=0.006824115756899118, zero_point=0, padding=(1, 1))\n",
       "        (bn2): Identity()\n",
       "        (relu2): Identity()\n",
       "        (conv3): QuantizedConv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), scale=0.010639126412570477, zero_point=57)\n",
       "        (bn3): Identity()\n",
       "        (float_add): QFunctional(\n",
       "          scale=0.022853178903460503, zero_point=26\n",
       "          (activation_post_process): Identity()\n",
       "        )\n",
       "        (relu3): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): QuantizedLinear(in_features=2048, out_features=1000, scale=0.19888177514076233, zero_point=0, qscheme=torch.per_channel_affine)\n",
       "  )\n",
       "  (quant): Quantize(scale=tensor([0.0407]), zero_point=tensor([59]), dtype=torch.quint8)\n",
       "  (dequant): DeQuantize()\n",
       ")"
      ]
     },
     "execution_count": 69,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quantized_model = torch.quantization.convert(quantized_model, inplace=True)\n",
    "\n",
    "quantized_model.eval()\n",
    "\n",
    "# Using high-level static quantization wrapper\n",
    "# The above steps, including torch.quantization.prepare, calibrate_model, and torch.quantization.convert, are also equivalent to\n",
    "# quantized_model = torch.quantization.quantize(model=quantized_model, run_fn=calibrate_model, run_args=[train_loader], mapping=None, inplace=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JgI3mDDzQqYN"
   },
   "source": [
    "## Examine Quantized Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3y8QaAQVQxOY"
   },
   "source": [
    "### Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 895445,
     "status": "ok",
     "timestamp": 1620653111625,
     "user": {
      "displayName": "Tim Shen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgNQrJ7jwDo36WwiK5d1fd2sl5mNxpQC8UsAvxjZw=s64",
      "userId": "18284420496267004524"
     },
     "user_tz": 240
    },
    "id": "QmoNGs6HQfXw",
    "outputId": "e6693313-7bca-419b-8b24-11af010532b8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QuantizedModel(\n",
      "  (model_fp32): ResNet(\n",
      "    (conv1): QuantizedConvReLU2d(3, 64, kernel_size=(3, 3), stride=(1, 1), scale=0.019204583019018173, zero_point=0, padding=(1, 1))\n",
      "    (bn1): Identity()\n",
      "    (relu): Identity()\n",
      "    (maxpool): Identity()\n",
      "    (layer1): Sequential(\n",
      "      (0): Bottleneck(\n",
      "        (conv1): QuantizedConvReLU2d(64, 64, kernel_size=(1, 1), stride=(1, 1), scale=0.012737809680402279, zero_point=0)\n",
      "        (bn1): Identity()\n",
      "        (relu1): Identity()\n",
      "        (conv2): QuantizedConvReLU2d(64, 64, kernel_size=(3, 3), stride=(1, 1), scale=0.012885705567896366, zero_point=0, padding=(1, 1))\n",
      "        (bn2): Identity()\n",
      "        (relu2): Identity()\n",
      "        (conv3): QuantizedConv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), scale=0.02152417227625847, zero_point=60)\n",
      "        (bn3): Identity()\n",
      "        (downsample): Sequential(\n",
      "          (0): QuantizedConv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), scale=0.022081870585680008, zero_point=64)\n",
      "          (1): Identity()\n",
      "        )\n",
      "        (float_add): QFunctional(\n",
      "          scale=0.03427840396761894, zero_point=68\n",
      "          (activation_post_process): Identity()\n",
      "        )\n",
      "        (relu3): ReLU(inplace=True)\n",
      "      )\n",
      "      (1): Bottleneck(\n",
      "        (conv1): QuantizedConvReLU2d(256, 64, kernel_size=(1, 1), stride=(1, 1), scale=0.011307698674499989, zero_point=0)\n",
      "        (bn1): Identity()\n",
      "        (relu1): Identity()\n",
      "        (conv2): QuantizedConvReLU2d(64, 64, kernel_size=(3, 3), stride=(1, 1), scale=0.009987350553274155, zero_point=0, padding=(1, 1))\n",
      "        (bn2): Identity()\n",
      "        (relu2): Identity()\n",
      "        (conv3): QuantizedConv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), scale=0.01072866190224886, zero_point=45)\n",
      "        (bn3): Identity()\n",
      "        (float_add): QFunctional(\n",
      "          scale=0.021105196326971054, zero_point=40\n",
      "          (activation_post_process): Identity()\n",
      "        )\n",
      "        (relu3): ReLU(inplace=True)\n",
      "      )\n",
      "      (2): Bottleneck(\n",
      "        (conv1): QuantizedConvReLU2d(256, 64, kernel_size=(1, 1), stride=(1, 1), scale=0.009221541695296764, zero_point=0)\n",
      "        (bn1): Identity()\n",
      "        (relu1): Identity()\n",
      "        (conv2): QuantizedConvReLU2d(64, 64, kernel_size=(3, 3), stride=(1, 1), scale=0.008502683602273464, zero_point=0, padding=(1, 1))\n",
      "        (bn2): Identity()\n",
      "        (relu2): Identity()\n",
      "        (conv3): QuantizedConv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), scale=0.013609272427856922, zero_point=54)\n",
      "        (bn3): Identity()\n",
      "        (float_add): QFunctional(\n",
      "          scale=0.022337842732667923, zero_point=35\n",
      "          (activation_post_process): Identity()\n",
      "        )\n",
      "        (relu3): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (layer2): Sequential(\n",
      "      (0): Bottleneck(\n",
      "        (conv1): QuantizedConvReLU2d(256, 128, kernel_size=(1, 1), stride=(1, 1), scale=0.012461054138839245, zero_point=0)\n",
      "        (bn1): Identity()\n",
      "        (relu1): Identity()\n",
      "        (conv2): QuantizedConvReLU2d(128, 128, kernel_size=(3, 3), stride=(2, 2), scale=0.015585375018417835, zero_point=0, padding=(1, 1))\n",
      "        (bn2): Identity()\n",
      "        (relu2): Identity()\n",
      "        (conv3): QuantizedConv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), scale=0.02590169757604599, zero_point=63)\n",
      "        (bn3): Identity()\n",
      "        (downsample): Sequential(\n",
      "          (0): QuantizedConv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), scale=0.027404462918639183, zero_point=60)\n",
      "          (1): Identity()\n",
      "        )\n",
      "        (float_add): QFunctional(\n",
      "          scale=0.030810300260782242, zero_point=55\n",
      "          (activation_post_process): Identity()\n",
      "        )\n",
      "        (relu3): ReLU(inplace=True)\n",
      "      )\n",
      "      (1): Bottleneck(\n",
      "        (conv1): QuantizedConvReLU2d(512, 128, kernel_size=(1, 1), stride=(1, 1), scale=0.005872565787285566, zero_point=0)\n",
      "        (bn1): Identity()\n",
      "        (relu1): Identity()\n",
      "        (conv2): QuantizedConvReLU2d(128, 128, kernel_size=(3, 3), stride=(1, 1), scale=0.006665462628006935, zero_point=0, padding=(1, 1))\n",
      "        (bn2): Identity()\n",
      "        (relu2): Identity()\n",
      "        (conv3): QuantizedConv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), scale=0.019667183980345726, zero_point=51)\n",
      "        (bn3): Identity()\n",
      "        (float_add): QFunctional(\n",
      "          scale=0.025235524401068687, zero_point=39\n",
      "          (activation_post_process): Identity()\n",
      "        )\n",
      "        (relu3): ReLU(inplace=True)\n",
      "      )\n",
      "      (2): Bottleneck(\n",
      "        (conv1): QuantizedConvReLU2d(512, 128, kernel_size=(1, 1), stride=(1, 1), scale=0.013361340388655663, zero_point=0)\n",
      "        (bn1): Identity()\n",
      "        (relu1): Identity()\n",
      "        (conv2): QuantizedConvReLU2d(128, 128, kernel_size=(3, 3), stride=(1, 1), scale=0.013233290053904057, zero_point=0, padding=(1, 1))\n",
      "        (bn2): Identity()\n",
      "        (relu2): Identity()\n",
      "        (conv3): QuantizedConv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), scale=0.020465465262532234, zero_point=62)\n",
      "        (bn3): Identity()\n",
      "        (float_add): QFunctional(\n",
      "          scale=0.026949772611260414, zero_point=47\n",
      "          (activation_post_process): Identity()\n",
      "        )\n",
      "        (relu3): ReLU(inplace=True)\n",
      "      )\n",
      "      (3): Bottleneck(\n",
      "        (conv1): QuantizedConvReLU2d(512, 128, kernel_size=(1, 1), stride=(1, 1), scale=0.009794543497264385, zero_point=0)\n",
      "        (bn1): Identity()\n",
      "        (relu1): Identity()\n",
      "        (conv2): QuantizedConvReLU2d(128, 128, kernel_size=(3, 3), stride=(1, 1), scale=0.011649079620838165, zero_point=0, padding=(1, 1))\n",
      "        (bn2): Identity()\n",
      "        (relu2): Identity()\n",
      "        (conv3): QuantizedConv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), scale=0.014204644598066807, zero_point=67)\n",
      "        (bn3): Identity()\n",
      "        (float_add): QFunctional(\n",
      "          scale=0.025248227640986443, zero_point=38\n",
      "          (activation_post_process): Identity()\n",
      "        )\n",
      "        (relu3): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (layer3): Sequential(\n",
      "      (0): Bottleneck(\n",
      "        (conv1): QuantizedConvReLU2d(512, 256, kernel_size=(1, 1), stride=(1, 1), scale=0.01306710485368967, zero_point=0)\n",
      "        (bn1): Identity()\n",
      "        (relu1): Identity()\n",
      "        (conv2): QuantizedConvReLU2d(256, 256, kernel_size=(3, 3), stride=(2, 2), scale=0.011053628288209438, zero_point=0, padding=(1, 1))\n",
      "        (bn2): Identity()\n",
      "        (relu2): Identity()\n",
      "        (conv3): QuantizedConv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), scale=0.013680469244718552, zero_point=61)\n",
      "        (bn3): Identity()\n",
      "        (downsample): Sequential(\n",
      "          (0): QuantizedConv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), scale=0.019680319353938103, zero_point=51)\n",
      "          (1): Identity()\n",
      "        )\n",
      "        (float_add): QFunctional(\n",
      "          scale=0.02075892500579357, zero_point=80\n",
      "          (activation_post_process): Identity()\n",
      "        )\n",
      "        (relu3): ReLU(inplace=True)\n",
      "      )\n",
      "      (1): Bottleneck(\n",
      "        (conv1): QuantizedConvReLU2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), scale=0.007657712325453758, zero_point=0)\n",
      "        (bn1): Identity()\n",
      "        (relu1): Identity()\n",
      "        (conv2): QuantizedConvReLU2d(256, 256, kernel_size=(3, 3), stride=(1, 1), scale=0.0074248467572033405, zero_point=0, padding=(1, 1))\n",
      "        (bn2): Identity()\n",
      "        (relu2): Identity()\n",
      "        (conv3): QuantizedConv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), scale=0.010591094382107258, zero_point=50)\n",
      "        (bn3): Identity()\n",
      "        (float_add): QFunctional(\n",
      "          scale=0.01918703503906727, zero_point=52\n",
      "          (activation_post_process): Identity()\n",
      "        )\n",
      "        (relu3): ReLU(inplace=True)\n",
      "      )\n",
      "      (2): Bottleneck(\n",
      "        (conv1): QuantizedConvReLU2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), scale=0.006215944886207581, zero_point=0)\n",
      "        (bn1): Identity()\n",
      "        (relu1): Identity()\n",
      "        (conv2): QuantizedConvReLU2d(256, 256, kernel_size=(3, 3), stride=(1, 1), scale=0.005813981872051954, zero_point=0, padding=(1, 1))\n",
      "        (bn2): Identity()\n",
      "        (relu2): Identity()\n",
      "        (conv3): QuantizedConv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), scale=0.011511526070535183, zero_point=84)\n",
      "        (bn3): Identity()\n",
      "        (float_add): QFunctional(\n",
      "          scale=0.014239568263292313, zero_point=63\n",
      "          (activation_post_process): Identity()\n",
      "        )\n",
      "        (relu3): ReLU(inplace=True)\n",
      "      )\n",
      "      (3): Bottleneck(\n",
      "        (conv1): QuantizedConvReLU2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), scale=0.007187293376773596, zero_point=0)\n",
      "        (bn1): Identity()\n",
      "        (relu1): Identity()\n",
      "        (conv2): QuantizedConvReLU2d(256, 256, kernel_size=(3, 3), stride=(1, 1), scale=0.005468515679240227, zero_point=0, padding=(1, 1))\n",
      "        (bn2): Identity()\n",
      "        (relu2): Identity()\n",
      "        (conv3): QuantizedConv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), scale=0.012946025468409061, zero_point=76)\n",
      "        (bn3): Identity()\n",
      "        (float_add): QFunctional(\n",
      "          scale=0.02151459828019142, zero_point=52\n",
      "          (activation_post_process): Identity()\n",
      "        )\n",
      "        (relu3): ReLU(inplace=True)\n",
      "      )\n",
      "      (4): Bottleneck(\n",
      "        (conv1): QuantizedConvReLU2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), scale=0.00799955241382122, zero_point=0)\n",
      "        (bn1): Identity()\n",
      "        (relu1): Identity()\n",
      "        (conv2): QuantizedConvReLU2d(256, 256, kernel_size=(3, 3), stride=(1, 1), scale=0.008165148086845875, zero_point=0, padding=(1, 1))\n",
      "        (bn2): Identity()\n",
      "        (relu2): Identity()\n",
      "        (conv3): QuantizedConv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), scale=0.01575191132724285, zero_point=65)\n",
      "        (bn3): Identity()\n",
      "        (float_add): QFunctional(\n",
      "          scale=0.01934295892715454, zero_point=56\n",
      "          (activation_post_process): Identity()\n",
      "        )\n",
      "        (relu3): ReLU(inplace=True)\n",
      "      )\n",
      "      (5): Bottleneck(\n",
      "        (conv1): QuantizedConvReLU2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), scale=0.009787699207663536, zero_point=0)\n",
      "        (bn1): Identity()\n",
      "        (relu1): Identity()\n",
      "        (conv2): QuantizedConvReLU2d(256, 256, kernel_size=(3, 3), stride=(1, 1), scale=0.01002961490303278, zero_point=0, padding=(1, 1))\n",
      "        (bn2): Identity()\n",
      "        (relu2): Identity()\n",
      "        (conv3): QuantizedConv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), scale=0.014187728054821491, zero_point=84)\n",
      "        (bn3): Identity()\n",
      "        (float_add): QFunctional(\n",
      "          scale=0.023536738008260727, zero_point=54\n",
      "          (activation_post_process): Identity()\n",
      "        )\n",
      "        (relu3): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (layer4): Sequential(\n",
      "      (0): Bottleneck(\n",
      "        (conv1): QuantizedConvReLU2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), scale=0.009980663657188416, zero_point=0)\n",
      "        (bn1): Identity()\n",
      "        (relu1): Identity()\n",
      "        (conv2): QuantizedConvReLU2d(512, 512, kernel_size=(3, 3), stride=(2, 2), scale=0.012923957780003548, zero_point=0, padding=(1, 1))\n",
      "        (bn2): Identity()\n",
      "        (relu2): Identity()\n",
      "        (conv3): QuantizedConv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), scale=0.019413603469729424, zero_point=46)\n",
      "        (bn3): Identity()\n",
      "        (downsample): Sequential(\n",
      "          (0): QuantizedConv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), scale=0.017441261559724808, zero_point=55)\n",
      "          (1): Identity()\n",
      "        )\n",
      "        (float_add): QFunctional(\n",
      "          scale=0.027488579973578453, zero_point=54\n",
      "          (activation_post_process): Identity()\n",
      "        )\n",
      "        (relu3): ReLU(inplace=True)\n",
      "      )\n",
      "      (1): Bottleneck(\n",
      "        (conv1): QuantizedConvReLU2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), scale=0.007200597319751978, zero_point=0)\n",
      "        (bn1): Identity()\n",
      "        (relu1): Identity()\n",
      "        (conv2): QuantizedConvReLU2d(512, 512, kernel_size=(3, 3), stride=(1, 1), scale=0.005463356617838144, zero_point=0, padding=(1, 1))\n",
      "        (bn2): Identity()\n",
      "        (relu2): Identity()\n",
      "        (conv3): QuantizedConv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), scale=0.013222944922745228, zero_point=52)\n",
      "        (bn3): Identity()\n",
      "        (float_add): QFunctional(\n",
      "          scale=0.023657996207475662, zero_point=37\n",
      "          (activation_post_process): Identity()\n",
      "        )\n",
      "        (relu3): ReLU(inplace=True)\n",
      "      )\n",
      "      (2): Bottleneck(\n",
      "        (conv1): QuantizedConvReLU2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), scale=0.009196601808071136, zero_point=0)\n",
      "        (bn1): Identity()\n",
      "        (relu1): Identity()\n",
      "        (conv2): QuantizedConvReLU2d(512, 512, kernel_size=(3, 3), stride=(1, 1), scale=0.009690864942967892, zero_point=0, padding=(1, 1))\n",
      "        (bn2): Identity()\n",
      "        (relu2): Identity()\n",
      "        (conv3): QuantizedConv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), scale=0.014281063340604305, zero_point=63)\n",
      "        (bn3): Identity()\n",
      "        (float_add): QFunctional(\n",
      "          scale=0.02598339505493641, zero_point=33\n",
      "          (activation_post_process): Identity()\n",
      "        )\n",
      "        (relu3): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "    (fc): QuantizedLinear(in_features=2048, out_features=1000, scale=0.22001603245735168, zero_point=0, qscheme=torch.per_channel_affine)\n",
      "  )\n",
      "  (quant): Quantize(scale=tensor([0.0407]), zero_point=tensor([59]), dtype=torch.quint8)\n",
      "  (dequant): DeQuantize()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(quantized_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "shpk3cL-Qzn6"
   },
   "source": [
    "### Param shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bVFRtuidQlG9"
   },
   "outputs": [],
   "source": [
    "# # ???\n",
    "# quantized_model.eval()\n",
    "# for name, param in quantized_model.named_parameters():\n",
    "#     print(name, param.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QBuC1Q8vyl5s"
   },
   "source": [
    "# Test Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dwQ011dNykyt"
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "def test(model, test_loader, criterion, device='cpu'):\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "\n",
    "    for data, target in test_loader:\n",
    "        with torch.no_grad():\n",
    "            data = data.to(device)\n",
    "            target = target.to(device)\n",
    "\n",
    "            outputs = model(data)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "\n",
    "            test_loss += criterion(outputs, target).item() * data.size(0)\n",
    "            correct += torch.sum(preds == target.data)\n",
    "\n",
    "    test_loss = test_loss / len(test_loader.dataset)\n",
    "    test_acc = 100.0 * correct / len(test_loader.dataset)\n",
    "\n",
    "    print('Test Loss: {:.4f}, Accuracy: {:.2f}%'.format(test_loss, test_acc))\n",
    "\n",
    "    return test_loss, test_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2EJWa4THytKR"
   },
   "source": [
    "## Test Acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 331052,
     "status": "ok",
     "timestamp": 1620766415228,
     "user": {
      "displayName": "Tim Shen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgNQrJ7jwDo36WwiK5d1fd2sl5mNxpQC8UsAvxjZw=s64",
      "userId": "18284420496267004524"
     },
     "user_tz": 240
    },
    "id": "vlPvtZ2PRMFD",
    "outputId": "0334b1cf-e5ba-4874-bab6-74eef1b9df71"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.2359, Accuracy: 93.55%\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = test(quantized_model, test_loader, criterion)\n",
    "# print(test_loss, test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vwjAQIt2PhCG"
   },
   "outputs": [],
   "source": [
    "torch.save(quantized_model.state_dict(), savepath + '{:.2f}_quantized.pt'.format(test_acc))\n",
    "\n",
    "# The saved module serializes all of the methods, submodules, parameters, and attributes of this module\n",
    "torch.jit.save(torch.jit.script(quantized_model), savepath + '{:.2f}_quantized_jit.pt'.format(test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 565825,
     "status": "ok",
     "timestamp": 1620691850240,
     "user": {
      "displayName": "Tim Shen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgNQrJ7jwDo36WwiK5d1fd2sl5mNxpQC8UsAvxjZw=s64",
      "userId": "18284420496267004524"
     },
     "user_tz": 240
    },
    "id": "RfeDQH3nA6VV",
    "outputId": "e576efee-d5b9-47e9-a2e9-fe7a0562398d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.2349, Accuracy: 93.62%\n"
     ]
    }
   ],
   "source": [
    "test_loss_fused, test_acc_fused = test(fused_model, test_loader, criterion)\n",
    "# print(test_loss, test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UPIt-N47T_AK"
   },
   "source": [
    "# Load Quantized Statedict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CIQ2VPYaWTpK"
   },
   "source": [
    "## final quantized model\n",
    "\n",
    "weight + bias + scale + zeropoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Bo7scBtlL6HZ"
   },
   "outputs": [],
   "source": [
    "# qmodel = torch.jit.load('./checkpoint/ResNet50_93.65_quantized_jit.pt', map_location=device)\n",
    "qmodel = torch.load('./checkpoint/ResNet50_93.65_quantized.pt', map_location=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 170,
     "status": "ok",
     "timestamp": 1620690796509,
     "user": {
      "displayName": "Tim Shen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgNQrJ7jwDo36WwiK5d1fd2sl5mNxpQC8UsAvxjZw=s64",
      "userId": "18284420496267004524"
     },
     "user_tz": 240
    },
    "id": "I1Zqz6yCUJ2w",
    "outputId": "e432c106-c8ca-490a-f22c-ba493f64eff2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_fp32.conv1.weight\n",
      "tensor([[[[  31,   59,   68],\n",
      "          [  95,  127,  115],\n",
      "          [  39,  121,   84]],\n",
      "\n",
      "         [[ -17,    5,   21],\n",
      "          [  16,   47,   27],\n",
      "          [ -29,  -13,    3]],\n",
      "\n",
      "         [[ -12,   -8,   -2],\n",
      "          [  16,    5,  -12],\n",
      "          [ -23,  -49,  -14]]],\n",
      "\n",
      "\n",
      "        [[[ -52,   10,   10],\n",
      "          [  -5,  127,   91],\n",
      "          [ -23,   78,   62]],\n",
      "\n",
      "         [[   0,  -47,  -34],\n",
      "          [ -23,  -60,  -65],\n",
      "          [   3,  -59,  -32]],\n",
      "\n",
      "         [[  49,   34,   32],\n",
      "          [  38,    1,   -8],\n",
      "          [  18,  -43,  -36]]],\n",
      "\n",
      "\n",
      "        [[[   7,    5,   12],\n",
      "          [ -36,  116,  108],\n",
      "          [ -64,  -54,   20]],\n",
      "\n",
      "         [[ -45,    3,   56],\n",
      "          [ -94,   65,  126],\n",
      "          [-114, -121,   11]],\n",
      "\n",
      "         [[ -18,    1,   24],\n",
      "          [ -30,  100,  127],\n",
      "          [ -83,  -52,   38]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ -47,  -56,   -7],\n",
      "          [ -28,   75,   -3],\n",
      "          [ -61,   -9,  -36]],\n",
      "\n",
      "         [[ -23,   18,   21],\n",
      "          [  40,  113,   66],\n",
      "          [ -27,   17,   11]],\n",
      "\n",
      "         [[  11,   45,   -9],\n",
      "          [  71,  127,  104],\n",
      "          [  43,   34,   68]]],\n",
      "\n",
      "\n",
      "        [[[  11,   74,   48],\n",
      "          [  19,   66,   39],\n",
      "          [ -41,  -96,  -74]],\n",
      "\n",
      "         [[  36,   89,   61],\n",
      "          [  23,   43,    4],\n",
      "          [ -54, -128, -108]],\n",
      "\n",
      "         [[  16,   61,   52],\n",
      "          [  29,   36,   19],\n",
      "          [ -32,  -79,  -67]]],\n",
      "\n",
      "\n",
      "        [[[   4,   40,   17],\n",
      "          [   9,   -3,   18],\n",
      "          [  -6,   -5,    5]],\n",
      "\n",
      "         [[   6,  -38,   -1],\n",
      "          [ -29, -127,  -50],\n",
      "          [  -1,  -76,  -33]],\n",
      "\n",
      "         [[  14,    8,   -6],\n",
      "          [  20,  -26,   -7],\n",
      "          [  29,  -18,    9]]]], dtype=torch.int8)\n"
     ]
    }
   ],
   "source": [
    "for name in qmodel:\n",
    "    print(name)\n",
    "    print(qmodel[name].int_repr())  # change the dtype from qint8 to int8\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lBAccdhsz08g"
   },
   "source": [
    "### Layer\n",
    "\n",
    "```\n",
    "model_fp32.layer1.0.conv1.weight\n",
    "model_fp32.layer1.0.conv1.bias\n",
    "model_fp32.layer1.0.conv1.scale\n",
    "model_fp32.layer1.0.conv1.zero_point\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VuT3-rtNKUcN"
   },
   "source": [
    "### Scale and Zero_point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 240,
     "status": "ok",
     "timestamp": 1620765812838,
     "user": {
      "displayName": "Tim Shen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgNQrJ7jwDo36WwiK5d1fd2sl5mNxpQC8UsAvxjZw=s64",
      "userId": "18284420496267004524"
     },
     "user_tz": 240
    },
    "id": "cI2CrzalKYMh",
    "outputId": "aa18b08e-4fb8-4ef0-a4a7-620aaa5a2abb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0106)\n",
      "tensor(0)\n"
     ]
    }
   ],
   "source": [
    "print(qmodel['model_fp32.layer1.0.conv1.scale'])\n",
    "print(qmodel['model_fp32.layer1.0.conv1.zero_point'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GdDJneNMV3IC"
   },
   "source": [
    "## fused model after calibration before convert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8XnD2N5MF6jF"
   },
   "outputs": [],
   "source": [
    "temp_model = torch.load('./checkpoint/ResNet50_2_temp.pt', map_location=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 220,
     "status": "ok",
     "timestamp": 1620765324590,
     "user": {
      "displayName": "Tim Shen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgNQrJ7jwDo36WwiK5d1fd2sl5mNxpQC8UsAvxjZw=s64",
      "userId": "18284420496267004524"
     },
     "user_tz": 240
    },
    "id": "yeLv5ARLGAqb",
    "outputId": "2c4d6c25-ce1d-4096-881e-860ef22af9ad"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.0052,  0.0098,  0.0113],\n",
       "          [ 0.0159,  0.0213,  0.0192],\n",
       "          [ 0.0065,  0.0202,  0.0141]],\n",
       "\n",
       "         [[-0.0028,  0.0009,  0.0035],\n",
       "          [ 0.0027,  0.0079,  0.0045],\n",
       "          [-0.0049, -0.0021,  0.0005]],\n",
       "\n",
       "         [[-0.0021, -0.0014, -0.0003],\n",
       "          [ 0.0027,  0.0009, -0.0020],\n",
       "          [-0.0038, -0.0081, -0.0024]]],\n",
       "\n",
       "\n",
       "        [[[-0.0917,  0.0178,  0.0173],\n",
       "          [-0.0085,  0.2263,  0.1618],\n",
       "          [-0.0414,  0.1392,  0.1105]],\n",
       "\n",
       "         [[-0.0004, -0.0831, -0.0612],\n",
       "          [-0.0415, -0.1068, -0.1160],\n",
       "          [ 0.0049, -0.1051, -0.0564]],\n",
       "\n",
       "         [[ 0.0864,  0.0610,  0.0573],\n",
       "          [ 0.0669,  0.0018, -0.0150],\n",
       "          [ 0.0312, -0.0766, -0.0639]]],\n",
       "\n",
       "\n",
       "        [[[ 0.0029,  0.0020,  0.0054],\n",
       "          [-0.0158,  0.0509,  0.0475],\n",
       "          [-0.0281, -0.0237,  0.0087]],\n",
       "\n",
       "         [[-0.0197,  0.0015,  0.0248],\n",
       "          [-0.0415,  0.0287,  0.0556],\n",
       "          [-0.0503, -0.0534,  0.0047]],\n",
       "\n",
       "         [[-0.0077,  0.0003,  0.0107],\n",
       "          [-0.0130,  0.0441,  0.0561],\n",
       "          [-0.0364, -0.0229,  0.0166]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[-0.0088, -0.0104, -0.0013],\n",
       "          [-0.0052,  0.0141, -0.0006],\n",
       "          [-0.0115, -0.0017, -0.0067]],\n",
       "\n",
       "         [[-0.0043,  0.0033,  0.0039],\n",
       "          [ 0.0074,  0.0210,  0.0122],\n",
       "          [-0.0051,  0.0031,  0.0020]],\n",
       "\n",
       "         [[ 0.0020,  0.0085, -0.0017],\n",
       "          [ 0.0132,  0.0238,  0.0193],\n",
       "          [ 0.0081,  0.0064,  0.0127]]],\n",
       "\n",
       "\n",
       "        [[[ 0.0082,  0.0534,  0.0346],\n",
       "          [ 0.0137,  0.0471,  0.0277],\n",
       "          [-0.0292, -0.0686, -0.0532]],\n",
       "\n",
       "         [[ 0.0257,  0.0638,  0.0437],\n",
       "          [ 0.0167,  0.0311,  0.0029],\n",
       "          [-0.0389, -0.0915, -0.0773]],\n",
       "\n",
       "         [[ 0.0115,  0.0437,  0.0373],\n",
       "          [ 0.0208,  0.0261,  0.0134],\n",
       "          [-0.0227, -0.0570, -0.0480]]],\n",
       "\n",
       "\n",
       "        [[[ 0.0025,  0.0250,  0.0107],\n",
       "          [ 0.0059, -0.0020,  0.0110],\n",
       "          [-0.0040, -0.0034,  0.0030]],\n",
       "\n",
       "         [[ 0.0040, -0.0236, -0.0005],\n",
       "          [-0.0184, -0.0801, -0.0312],\n",
       "          [-0.0005, -0.0480, -0.0205]],\n",
       "\n",
       "         [[ 0.0090,  0.0050, -0.0038],\n",
       "          [ 0.0124, -0.0165, -0.0044],\n",
       "          [ 0.0181, -0.0114,  0.0059]]]])"
      ]
     },
     "execution_count": 57,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for name in temp_model:\n",
    "#     print(name)\n",
    "#     print(temp_model[name])\n",
    "#     break\n",
    "\n",
    "temp_model['model_fp32.conv1.0.weight']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9qQO7MmxGpga"
   },
   "source": [
    "### Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 839,
     "status": "ok",
     "timestamp": 1620764678554,
     "user": {
      "displayName": "Tim Shen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgNQrJ7jwDo36WwiK5d1fd2sl5mNxpQC8UsAvxjZw=s64",
      "userId": "18284420496267004524"
     },
     "user_tz": 240
    },
    "id": "HH83cWiuGkaN",
    "outputId": "5886bb1b-cec2-46ad-b82e-b07309291226"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_fp32.conv1.0.weight\n",
      "model_fp32.conv1.0.bias\n",
      "model_fp32.conv1.activation_post_process.eps\n",
      "model_fp32.conv1.activation_post_process.histogram\n",
      "model_fp32.conv1.activation_post_process.min_val\n",
      "model_fp32.conv1.activation_post_process.max_val\n",
      "model_fp32.layer1.0.conv1.0.weight\n",
      "model_fp32.layer1.0.conv1.0.bias\n",
      "model_fp32.layer1.0.conv1.activation_post_process.eps\n",
      "model_fp32.layer1.0.conv1.activation_post_process.histogram\n",
      "model_fp32.layer1.0.conv1.activation_post_process.min_val\n",
      "model_fp32.layer1.0.conv1.activation_post_process.max_val\n",
      "model_fp32.layer1.0.conv2.0.weight\n",
      "model_fp32.layer1.0.conv2.0.bias\n",
      "model_fp32.layer1.0.conv2.activation_post_process.eps\n",
      "model_fp32.layer1.0.conv2.activation_post_process.histogram\n",
      "model_fp32.layer1.0.conv2.activation_post_process.min_val\n",
      "model_fp32.layer1.0.conv2.activation_post_process.max_val\n",
      "model_fp32.layer1.0.conv3.weight\n",
      "model_fp32.layer1.0.conv3.bias\n",
      "model_fp32.layer1.0.conv3.activation_post_process.eps\n",
      "model_fp32.layer1.0.conv3.activation_post_process.histogram\n",
      "model_fp32.layer1.0.conv3.activation_post_process.min_val\n",
      "model_fp32.layer1.0.conv3.activation_post_process.max_val\n",
      "model_fp32.layer1.0.downsample.0.weight\n",
      "model_fp32.layer1.0.downsample.0.bias\n",
      "model_fp32.layer1.0.downsample.0.activation_post_process.eps\n",
      "model_fp32.layer1.0.downsample.0.activation_post_process.histogram\n",
      "model_fp32.layer1.0.downsample.0.activation_post_process.min_val\n",
      "model_fp32.layer1.0.downsample.0.activation_post_process.max_val\n",
      "model_fp32.layer1.0.float_add.activation_post_process.eps\n",
      "model_fp32.layer1.0.float_add.activation_post_process.histogram\n",
      "model_fp32.layer1.0.float_add.activation_post_process.min_val\n",
      "model_fp32.layer1.0.float_add.activation_post_process.max_val\n",
      "model_fp32.layer1.1.conv1.0.weight\n",
      "model_fp32.layer1.1.conv1.0.bias\n",
      "model_fp32.layer1.1.conv1.activation_post_process.eps\n",
      "model_fp32.layer1.1.conv1.activation_post_process.histogram\n",
      "model_fp32.layer1.1.conv1.activation_post_process.min_val\n",
      "model_fp32.layer1.1.conv1.activation_post_process.max_val\n",
      "model_fp32.layer1.1.conv2.0.weight\n",
      "model_fp32.layer1.1.conv2.0.bias\n",
      "model_fp32.layer1.1.conv2.activation_post_process.eps\n",
      "model_fp32.layer1.1.conv2.activation_post_process.histogram\n",
      "model_fp32.layer1.1.conv2.activation_post_process.min_val\n",
      "model_fp32.layer1.1.conv2.activation_post_process.max_val\n",
      "model_fp32.layer1.1.conv3.weight\n",
      "model_fp32.layer1.1.conv3.bias\n",
      "model_fp32.layer1.1.conv3.activation_post_process.eps\n",
      "model_fp32.layer1.1.conv3.activation_post_process.histogram\n",
      "model_fp32.layer1.1.conv3.activation_post_process.min_val\n",
      "model_fp32.layer1.1.conv3.activation_post_process.max_val\n",
      "model_fp32.layer1.1.float_add.activation_post_process.eps\n",
      "model_fp32.layer1.1.float_add.activation_post_process.histogram\n",
      "model_fp32.layer1.1.float_add.activation_post_process.min_val\n",
      "model_fp32.layer1.1.float_add.activation_post_process.max_val\n",
      "model_fp32.layer1.2.conv1.0.weight\n",
      "model_fp32.layer1.2.conv1.0.bias\n",
      "model_fp32.layer1.2.conv1.activation_post_process.eps\n",
      "model_fp32.layer1.2.conv1.activation_post_process.histogram\n",
      "model_fp32.layer1.2.conv1.activation_post_process.min_val\n",
      "model_fp32.layer1.2.conv1.activation_post_process.max_val\n",
      "model_fp32.layer1.2.conv2.0.weight\n",
      "model_fp32.layer1.2.conv2.0.bias\n",
      "model_fp32.layer1.2.conv2.activation_post_process.eps\n",
      "model_fp32.layer1.2.conv2.activation_post_process.histogram\n",
      "model_fp32.layer1.2.conv2.activation_post_process.min_val\n",
      "model_fp32.layer1.2.conv2.activation_post_process.max_val\n",
      "model_fp32.layer1.2.conv3.weight\n",
      "model_fp32.layer1.2.conv3.bias\n",
      "model_fp32.layer1.2.conv3.activation_post_process.eps\n",
      "model_fp32.layer1.2.conv3.activation_post_process.histogram\n",
      "model_fp32.layer1.2.conv3.activation_post_process.min_val\n",
      "model_fp32.layer1.2.conv3.activation_post_process.max_val\n",
      "model_fp32.layer1.2.float_add.activation_post_process.eps\n",
      "model_fp32.layer1.2.float_add.activation_post_process.histogram\n",
      "model_fp32.layer1.2.float_add.activation_post_process.min_val\n",
      "model_fp32.layer1.2.float_add.activation_post_process.max_val\n",
      "model_fp32.layer2.0.conv1.0.weight\n",
      "model_fp32.layer2.0.conv1.0.bias\n",
      "model_fp32.layer2.0.conv1.activation_post_process.eps\n",
      "model_fp32.layer2.0.conv1.activation_post_process.histogram\n",
      "model_fp32.layer2.0.conv1.activation_post_process.min_val\n",
      "model_fp32.layer2.0.conv1.activation_post_process.max_val\n",
      "model_fp32.layer2.0.conv2.0.weight\n",
      "model_fp32.layer2.0.conv2.0.bias\n",
      "model_fp32.layer2.0.conv2.activation_post_process.eps\n",
      "model_fp32.layer2.0.conv2.activation_post_process.histogram\n",
      "model_fp32.layer2.0.conv2.activation_post_process.min_val\n",
      "model_fp32.layer2.0.conv2.activation_post_process.max_val\n",
      "model_fp32.layer2.0.conv3.weight\n",
      "model_fp32.layer2.0.conv3.bias\n",
      "model_fp32.layer2.0.conv3.activation_post_process.eps\n",
      "model_fp32.layer2.0.conv3.activation_post_process.histogram\n",
      "model_fp32.layer2.0.conv3.activation_post_process.min_val\n",
      "model_fp32.layer2.0.conv3.activation_post_process.max_val\n",
      "model_fp32.layer2.0.downsample.0.weight\n",
      "model_fp32.layer2.0.downsample.0.bias\n",
      "model_fp32.layer2.0.downsample.0.activation_post_process.eps\n",
      "model_fp32.layer2.0.downsample.0.activation_post_process.histogram\n",
      "model_fp32.layer2.0.downsample.0.activation_post_process.min_val\n",
      "model_fp32.layer2.0.downsample.0.activation_post_process.max_val\n",
      "model_fp32.layer2.0.float_add.activation_post_process.eps\n",
      "model_fp32.layer2.0.float_add.activation_post_process.histogram\n",
      "model_fp32.layer2.0.float_add.activation_post_process.min_val\n",
      "model_fp32.layer2.0.float_add.activation_post_process.max_val\n",
      "model_fp32.layer2.1.conv1.0.weight\n",
      "model_fp32.layer2.1.conv1.0.bias\n",
      "model_fp32.layer2.1.conv1.activation_post_process.eps\n",
      "model_fp32.layer2.1.conv1.activation_post_process.histogram\n",
      "model_fp32.layer2.1.conv1.activation_post_process.min_val\n",
      "model_fp32.layer2.1.conv1.activation_post_process.max_val\n",
      "model_fp32.layer2.1.conv2.0.weight\n",
      "model_fp32.layer2.1.conv2.0.bias\n",
      "model_fp32.layer2.1.conv2.activation_post_process.eps\n",
      "model_fp32.layer2.1.conv2.activation_post_process.histogram\n",
      "model_fp32.layer2.1.conv2.activation_post_process.min_val\n",
      "model_fp32.layer2.1.conv2.activation_post_process.max_val\n",
      "model_fp32.layer2.1.conv3.weight\n",
      "model_fp32.layer2.1.conv3.bias\n",
      "model_fp32.layer2.1.conv3.activation_post_process.eps\n",
      "model_fp32.layer2.1.conv3.activation_post_process.histogram\n",
      "model_fp32.layer2.1.conv3.activation_post_process.min_val\n",
      "model_fp32.layer2.1.conv3.activation_post_process.max_val\n",
      "model_fp32.layer2.1.float_add.activation_post_process.eps\n",
      "model_fp32.layer2.1.float_add.activation_post_process.histogram\n",
      "model_fp32.layer2.1.float_add.activation_post_process.min_val\n",
      "model_fp32.layer2.1.float_add.activation_post_process.max_val\n",
      "model_fp32.layer2.2.conv1.0.weight\n",
      "model_fp32.layer2.2.conv1.0.bias\n",
      "model_fp32.layer2.2.conv1.activation_post_process.eps\n",
      "model_fp32.layer2.2.conv1.activation_post_process.histogram\n",
      "model_fp32.layer2.2.conv1.activation_post_process.min_val\n",
      "model_fp32.layer2.2.conv1.activation_post_process.max_val\n",
      "model_fp32.layer2.2.conv2.0.weight\n",
      "model_fp32.layer2.2.conv2.0.bias\n",
      "model_fp32.layer2.2.conv2.activation_post_process.eps\n",
      "model_fp32.layer2.2.conv2.activation_post_process.histogram\n",
      "model_fp32.layer2.2.conv2.activation_post_process.min_val\n",
      "model_fp32.layer2.2.conv2.activation_post_process.max_val\n",
      "model_fp32.layer2.2.conv3.weight\n",
      "model_fp32.layer2.2.conv3.bias\n",
      "model_fp32.layer2.2.conv3.activation_post_process.eps\n",
      "model_fp32.layer2.2.conv3.activation_post_process.histogram\n",
      "model_fp32.layer2.2.conv3.activation_post_process.min_val\n",
      "model_fp32.layer2.2.conv3.activation_post_process.max_val\n",
      "model_fp32.layer2.2.float_add.activation_post_process.eps\n",
      "model_fp32.layer2.2.float_add.activation_post_process.histogram\n",
      "model_fp32.layer2.2.float_add.activation_post_process.min_val\n",
      "model_fp32.layer2.2.float_add.activation_post_process.max_val\n",
      "model_fp32.layer2.3.conv1.0.weight\n",
      "model_fp32.layer2.3.conv1.0.bias\n",
      "model_fp32.layer2.3.conv1.activation_post_process.eps\n",
      "model_fp32.layer2.3.conv1.activation_post_process.histogram\n",
      "model_fp32.layer2.3.conv1.activation_post_process.min_val\n",
      "model_fp32.layer2.3.conv1.activation_post_process.max_val\n",
      "model_fp32.layer2.3.conv2.0.weight\n",
      "model_fp32.layer2.3.conv2.0.bias\n",
      "model_fp32.layer2.3.conv2.activation_post_process.eps\n",
      "model_fp32.layer2.3.conv2.activation_post_process.histogram\n",
      "model_fp32.layer2.3.conv2.activation_post_process.min_val\n",
      "model_fp32.layer2.3.conv2.activation_post_process.max_val\n",
      "model_fp32.layer2.3.conv3.weight\n",
      "model_fp32.layer2.3.conv3.bias\n",
      "model_fp32.layer2.3.conv3.activation_post_process.eps\n",
      "model_fp32.layer2.3.conv3.activation_post_process.histogram\n",
      "model_fp32.layer2.3.conv3.activation_post_process.min_val\n",
      "model_fp32.layer2.3.conv3.activation_post_process.max_val\n",
      "model_fp32.layer2.3.float_add.activation_post_process.eps\n",
      "model_fp32.layer2.3.float_add.activation_post_process.histogram\n",
      "model_fp32.layer2.3.float_add.activation_post_process.min_val\n",
      "model_fp32.layer2.3.float_add.activation_post_process.max_val\n",
      "model_fp32.layer3.0.conv1.0.weight\n",
      "model_fp32.layer3.0.conv1.0.bias\n",
      "model_fp32.layer3.0.conv1.activation_post_process.eps\n",
      "model_fp32.layer3.0.conv1.activation_post_process.histogram\n",
      "model_fp32.layer3.0.conv1.activation_post_process.min_val\n",
      "model_fp32.layer3.0.conv1.activation_post_process.max_val\n",
      "model_fp32.layer3.0.conv2.0.weight\n",
      "model_fp32.layer3.0.conv2.0.bias\n",
      "model_fp32.layer3.0.conv2.activation_post_process.eps\n",
      "model_fp32.layer3.0.conv2.activation_post_process.histogram\n",
      "model_fp32.layer3.0.conv2.activation_post_process.min_val\n",
      "model_fp32.layer3.0.conv2.activation_post_process.max_val\n",
      "model_fp32.layer3.0.conv3.weight\n",
      "model_fp32.layer3.0.conv3.bias\n",
      "model_fp32.layer3.0.conv3.activation_post_process.eps\n",
      "model_fp32.layer3.0.conv3.activation_post_process.histogram\n",
      "model_fp32.layer3.0.conv3.activation_post_process.min_val\n",
      "model_fp32.layer3.0.conv3.activation_post_process.max_val\n",
      "model_fp32.layer3.0.downsample.0.weight\n",
      "model_fp32.layer3.0.downsample.0.bias\n",
      "model_fp32.layer3.0.downsample.0.activation_post_process.eps\n",
      "model_fp32.layer3.0.downsample.0.activation_post_process.histogram\n",
      "model_fp32.layer3.0.downsample.0.activation_post_process.min_val\n",
      "model_fp32.layer3.0.downsample.0.activation_post_process.max_val\n",
      "model_fp32.layer3.0.float_add.activation_post_process.eps\n",
      "model_fp32.layer3.0.float_add.activation_post_process.histogram\n",
      "model_fp32.layer3.0.float_add.activation_post_process.min_val\n",
      "model_fp32.layer3.0.float_add.activation_post_process.max_val\n",
      "model_fp32.layer3.1.conv1.0.weight\n",
      "model_fp32.layer3.1.conv1.0.bias\n",
      "model_fp32.layer3.1.conv1.activation_post_process.eps\n",
      "model_fp32.layer3.1.conv1.activation_post_process.histogram\n",
      "model_fp32.layer3.1.conv1.activation_post_process.min_val\n",
      "model_fp32.layer3.1.conv1.activation_post_process.max_val\n",
      "model_fp32.layer3.1.conv2.0.weight\n",
      "model_fp32.layer3.1.conv2.0.bias\n",
      "model_fp32.layer3.1.conv2.activation_post_process.eps\n",
      "model_fp32.layer3.1.conv2.activation_post_process.histogram\n",
      "model_fp32.layer3.1.conv2.activation_post_process.min_val\n",
      "model_fp32.layer3.1.conv2.activation_post_process.max_val\n",
      "model_fp32.layer3.1.conv3.weight\n",
      "model_fp32.layer3.1.conv3.bias\n",
      "model_fp32.layer3.1.conv3.activation_post_process.eps\n",
      "model_fp32.layer3.1.conv3.activation_post_process.histogram\n",
      "model_fp32.layer3.1.conv3.activation_post_process.min_val\n",
      "model_fp32.layer3.1.conv3.activation_post_process.max_val\n",
      "model_fp32.layer3.1.float_add.activation_post_process.eps\n",
      "model_fp32.layer3.1.float_add.activation_post_process.histogram\n",
      "model_fp32.layer3.1.float_add.activation_post_process.min_val\n",
      "model_fp32.layer3.1.float_add.activation_post_process.max_val\n",
      "model_fp32.layer3.2.conv1.0.weight\n",
      "model_fp32.layer3.2.conv1.0.bias\n",
      "model_fp32.layer3.2.conv1.activation_post_process.eps\n",
      "model_fp32.layer3.2.conv1.activation_post_process.histogram\n",
      "model_fp32.layer3.2.conv1.activation_post_process.min_val\n",
      "model_fp32.layer3.2.conv1.activation_post_process.max_val\n",
      "model_fp32.layer3.2.conv2.0.weight\n",
      "model_fp32.layer3.2.conv2.0.bias\n",
      "model_fp32.layer3.2.conv2.activation_post_process.eps\n",
      "model_fp32.layer3.2.conv2.activation_post_process.histogram\n",
      "model_fp32.layer3.2.conv2.activation_post_process.min_val\n",
      "model_fp32.layer3.2.conv2.activation_post_process.max_val\n",
      "model_fp32.layer3.2.conv3.weight\n",
      "model_fp32.layer3.2.conv3.bias\n",
      "model_fp32.layer3.2.conv3.activation_post_process.eps\n",
      "model_fp32.layer3.2.conv3.activation_post_process.histogram\n",
      "model_fp32.layer3.2.conv3.activation_post_process.min_val\n",
      "model_fp32.layer3.2.conv3.activation_post_process.max_val\n",
      "model_fp32.layer3.2.float_add.activation_post_process.eps\n",
      "model_fp32.layer3.2.float_add.activation_post_process.histogram\n",
      "model_fp32.layer3.2.float_add.activation_post_process.min_val\n",
      "model_fp32.layer3.2.float_add.activation_post_process.max_val\n",
      "model_fp32.layer3.3.conv1.0.weight\n",
      "model_fp32.layer3.3.conv1.0.bias\n",
      "model_fp32.layer3.3.conv1.activation_post_process.eps\n",
      "model_fp32.layer3.3.conv1.activation_post_process.histogram\n",
      "model_fp32.layer3.3.conv1.activation_post_process.min_val\n",
      "model_fp32.layer3.3.conv1.activation_post_process.max_val\n",
      "model_fp32.layer3.3.conv2.0.weight\n",
      "model_fp32.layer3.3.conv2.0.bias\n",
      "model_fp32.layer3.3.conv2.activation_post_process.eps\n",
      "model_fp32.layer3.3.conv2.activation_post_process.histogram\n",
      "model_fp32.layer3.3.conv2.activation_post_process.min_val\n",
      "model_fp32.layer3.3.conv2.activation_post_process.max_val\n",
      "model_fp32.layer3.3.conv3.weight\n",
      "model_fp32.layer3.3.conv3.bias\n",
      "model_fp32.layer3.3.conv3.activation_post_process.eps\n",
      "model_fp32.layer3.3.conv3.activation_post_process.histogram\n",
      "model_fp32.layer3.3.conv3.activation_post_process.min_val\n",
      "model_fp32.layer3.3.conv3.activation_post_process.max_val\n",
      "model_fp32.layer3.3.float_add.activation_post_process.eps\n",
      "model_fp32.layer3.3.float_add.activation_post_process.histogram\n",
      "model_fp32.layer3.3.float_add.activation_post_process.min_val\n",
      "model_fp32.layer3.3.float_add.activation_post_process.max_val\n",
      "model_fp32.layer3.4.conv1.0.weight\n",
      "model_fp32.layer3.4.conv1.0.bias\n",
      "model_fp32.layer3.4.conv1.activation_post_process.eps\n",
      "model_fp32.layer3.4.conv1.activation_post_process.histogram\n",
      "model_fp32.layer3.4.conv1.activation_post_process.min_val\n",
      "model_fp32.layer3.4.conv1.activation_post_process.max_val\n",
      "model_fp32.layer3.4.conv2.0.weight\n",
      "model_fp32.layer3.4.conv2.0.bias\n",
      "model_fp32.layer3.4.conv2.activation_post_process.eps\n",
      "model_fp32.layer3.4.conv2.activation_post_process.histogram\n",
      "model_fp32.layer3.4.conv2.activation_post_process.min_val\n",
      "model_fp32.layer3.4.conv2.activation_post_process.max_val\n",
      "model_fp32.layer3.4.conv3.weight\n",
      "model_fp32.layer3.4.conv3.bias\n",
      "model_fp32.layer3.4.conv3.activation_post_process.eps\n",
      "model_fp32.layer3.4.conv3.activation_post_process.histogram\n",
      "model_fp32.layer3.4.conv3.activation_post_process.min_val\n",
      "model_fp32.layer3.4.conv3.activation_post_process.max_val\n",
      "model_fp32.layer3.4.float_add.activation_post_process.eps\n",
      "model_fp32.layer3.4.float_add.activation_post_process.histogram\n",
      "model_fp32.layer3.4.float_add.activation_post_process.min_val\n",
      "model_fp32.layer3.4.float_add.activation_post_process.max_val\n",
      "model_fp32.layer3.5.conv1.0.weight\n",
      "model_fp32.layer3.5.conv1.0.bias\n",
      "model_fp32.layer3.5.conv1.activation_post_process.eps\n",
      "model_fp32.layer3.5.conv1.activation_post_process.histogram\n",
      "model_fp32.layer3.5.conv1.activation_post_process.min_val\n",
      "model_fp32.layer3.5.conv1.activation_post_process.max_val\n",
      "model_fp32.layer3.5.conv2.0.weight\n",
      "model_fp32.layer3.5.conv2.0.bias\n",
      "model_fp32.layer3.5.conv2.activation_post_process.eps\n",
      "model_fp32.layer3.5.conv2.activation_post_process.histogram\n",
      "model_fp32.layer3.5.conv2.activation_post_process.min_val\n",
      "model_fp32.layer3.5.conv2.activation_post_process.max_val\n",
      "model_fp32.layer3.5.conv3.weight\n",
      "model_fp32.layer3.5.conv3.bias\n",
      "model_fp32.layer3.5.conv3.activation_post_process.eps\n",
      "model_fp32.layer3.5.conv3.activation_post_process.histogram\n",
      "model_fp32.layer3.5.conv3.activation_post_process.min_val\n",
      "model_fp32.layer3.5.conv3.activation_post_process.max_val\n",
      "model_fp32.layer3.5.float_add.activation_post_process.eps\n",
      "model_fp32.layer3.5.float_add.activation_post_process.histogram\n",
      "model_fp32.layer3.5.float_add.activation_post_process.min_val\n",
      "model_fp32.layer3.5.float_add.activation_post_process.max_val\n",
      "model_fp32.layer4.0.conv1.0.weight\n",
      "model_fp32.layer4.0.conv1.0.bias\n",
      "model_fp32.layer4.0.conv1.activation_post_process.eps\n",
      "model_fp32.layer4.0.conv1.activation_post_process.histogram\n",
      "model_fp32.layer4.0.conv1.activation_post_process.min_val\n",
      "model_fp32.layer4.0.conv1.activation_post_process.max_val\n",
      "model_fp32.layer4.0.conv2.0.weight\n",
      "model_fp32.layer4.0.conv2.0.bias\n",
      "model_fp32.layer4.0.conv2.activation_post_process.eps\n",
      "model_fp32.layer4.0.conv2.activation_post_process.histogram\n",
      "model_fp32.layer4.0.conv2.activation_post_process.min_val\n",
      "model_fp32.layer4.0.conv2.activation_post_process.max_val\n",
      "model_fp32.layer4.0.conv3.weight\n",
      "model_fp32.layer4.0.conv3.bias\n",
      "model_fp32.layer4.0.conv3.activation_post_process.eps\n",
      "model_fp32.layer4.0.conv3.activation_post_process.histogram\n",
      "model_fp32.layer4.0.conv3.activation_post_process.min_val\n",
      "model_fp32.layer4.0.conv3.activation_post_process.max_val\n",
      "model_fp32.layer4.0.downsample.0.weight\n",
      "model_fp32.layer4.0.downsample.0.bias\n",
      "model_fp32.layer4.0.downsample.0.activation_post_process.eps\n",
      "model_fp32.layer4.0.downsample.0.activation_post_process.histogram\n",
      "model_fp32.layer4.0.downsample.0.activation_post_process.min_val\n",
      "model_fp32.layer4.0.downsample.0.activation_post_process.max_val\n",
      "model_fp32.layer4.0.float_add.activation_post_process.eps\n",
      "model_fp32.layer4.0.float_add.activation_post_process.histogram\n",
      "model_fp32.layer4.0.float_add.activation_post_process.min_val\n",
      "model_fp32.layer4.0.float_add.activation_post_process.max_val\n",
      "model_fp32.layer4.1.conv1.0.weight\n",
      "model_fp32.layer4.1.conv1.0.bias\n",
      "model_fp32.layer4.1.conv1.activation_post_process.eps\n",
      "model_fp32.layer4.1.conv1.activation_post_process.histogram\n",
      "model_fp32.layer4.1.conv1.activation_post_process.min_val\n",
      "model_fp32.layer4.1.conv1.activation_post_process.max_val\n",
      "model_fp32.layer4.1.conv2.0.weight\n",
      "model_fp32.layer4.1.conv2.0.bias\n",
      "model_fp32.layer4.1.conv2.activation_post_process.eps\n",
      "model_fp32.layer4.1.conv2.activation_post_process.histogram\n",
      "model_fp32.layer4.1.conv2.activation_post_process.min_val\n",
      "model_fp32.layer4.1.conv2.activation_post_process.max_val\n",
      "model_fp32.layer4.1.conv3.weight\n",
      "model_fp32.layer4.1.conv3.bias\n",
      "model_fp32.layer4.1.conv3.activation_post_process.eps\n",
      "model_fp32.layer4.1.conv3.activation_post_process.histogram\n",
      "model_fp32.layer4.1.conv3.activation_post_process.min_val\n",
      "model_fp32.layer4.1.conv3.activation_post_process.max_val\n",
      "model_fp32.layer4.1.float_add.activation_post_process.eps\n",
      "model_fp32.layer4.1.float_add.activation_post_process.histogram\n",
      "model_fp32.layer4.1.float_add.activation_post_process.min_val\n",
      "model_fp32.layer4.1.float_add.activation_post_process.max_val\n",
      "model_fp32.layer4.2.conv1.0.weight\n",
      "model_fp32.layer4.2.conv1.0.bias\n",
      "model_fp32.layer4.2.conv1.activation_post_process.eps\n",
      "model_fp32.layer4.2.conv1.activation_post_process.histogram\n",
      "model_fp32.layer4.2.conv1.activation_post_process.min_val\n",
      "model_fp32.layer4.2.conv1.activation_post_process.max_val\n",
      "model_fp32.layer4.2.conv2.0.weight\n",
      "model_fp32.layer4.2.conv2.0.bias\n",
      "model_fp32.layer4.2.conv2.activation_post_process.eps\n",
      "model_fp32.layer4.2.conv2.activation_post_process.histogram\n",
      "model_fp32.layer4.2.conv2.activation_post_process.min_val\n",
      "model_fp32.layer4.2.conv2.activation_post_process.max_val\n",
      "model_fp32.layer4.2.conv3.weight\n",
      "model_fp32.layer4.2.conv3.bias\n",
      "model_fp32.layer4.2.conv3.activation_post_process.eps\n",
      "model_fp32.layer4.2.conv3.activation_post_process.histogram\n",
      "model_fp32.layer4.2.conv3.activation_post_process.min_val\n",
      "model_fp32.layer4.2.conv3.activation_post_process.max_val\n",
      "model_fp32.layer4.2.float_add.activation_post_process.eps\n",
      "model_fp32.layer4.2.float_add.activation_post_process.histogram\n",
      "model_fp32.layer4.2.float_add.activation_post_process.min_val\n",
      "model_fp32.layer4.2.float_add.activation_post_process.max_val\n",
      "model_fp32.fc.weight\n",
      "model_fp32.fc.bias\n",
      "model_fp32.fc.activation_post_process.eps\n",
      "model_fp32.fc.activation_post_process.histogram\n",
      "model_fp32.fc.activation_post_process.min_val\n",
      "model_fp32.fc.activation_post_process.max_val\n",
      "quant.activation_post_process.eps\n",
      "quant.activation_post_process.histogram\n",
      "quant.activation_post_process.min_val\n",
      "quant.activation_post_process.max_val\n"
     ]
    }
   ],
   "source": [
    "for name in temp_model:\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JwBim_MDH3Da"
   },
   "source": [
    "### Histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 231,
     "status": "ok",
     "timestamp": 1620765365765,
     "user": {
      "displayName": "Tim Shen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgNQrJ7jwDo36WwiK5d1fd2sl5mNxpQC8UsAvxjZw=s64",
      "userId": "18284420496267004524"
     },
     "user_tz": 240
    },
    "id": "k2mU2hDCIB0g",
    "outputId": "33534b01-db02-4348-dff4-f2762d42aabc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([4.3272e+07, 2.3522e+05, 2.3464e+05,  ..., 0.0000e+00, 0.0000e+00,\n",
      "        2.0000e+00])\n",
      "2048\n"
     ]
    }
   ],
   "source": [
    "print(temp_model['model_fp32.layer1.0.conv2.activation_post_process.histogram'])\n",
    "print(len(temp_model['model_fp32.layer1.0.conv2.activation_post_process.histogram']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "51eHTFaeH7nY"
   },
   "source": [
    "### Eps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 229,
     "status": "ok",
     "timestamp": 1620765381741,
     "user": {
      "displayName": "Tim Shen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgNQrJ7jwDo36WwiK5d1fd2sl5mNxpQC8UsAvxjZw=s64",
      "userId": "18284420496267004524"
     },
     "user_tz": 240
    },
    "id": "t_Hay0vaIJyJ",
    "outputId": "1c6ec7e9-9742-4705-c178-59fb43da67f8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.1921e-07])\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print(temp_model['model_fp32.layer1.0.conv2.activation_post_process.eps'])\n",
    "print(len(temp_model['model_fp32.layer1.0.conv2.activation_post_process.eps']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N0ziZU8WH9ws"
   },
   "source": [
    "### Min / Max Val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 268,
     "status": "ok",
     "timestamp": 1620765408352,
     "user": {
      "displayName": "Tim Shen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgNQrJ7jwDo36WwiK5d1fd2sl5mNxpQC8UsAvxjZw=s64",
      "userId": "18284420496267004524"
     },
     "user_tz": 240
    },
    "id": "KdrqbRPbITtk",
    "outputId": "0e842f3d-8fbc-473e-e678-6a0ba35184cd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.)\n",
      "tensor(2.7615)\n"
     ]
    }
   ],
   "source": [
    "print(temp_model['model_fp32.layer1.0.conv2.activation_post_process.min_val'])\n",
    "print(temp_model['model_fp32.layer1.0.conv2.activation_post_process.max_val'])"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "ResNet50_cifar_built-in_quantize.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "jupytext": {
   "formats": "ipynb,auto:percent"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
